{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7366ca2f-131b-4960-8feb-883d59f7df90",
   "metadata": {},
   "source": [
    "# Simplicit: Simulating Implicit Objects\n",
    "The implicit simulation pipeline is divided into 7 steps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a67ed-fdf9-46db-8cdd-205abbe1d2f0",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2fcef6-ba57-4999-b81e-e9c2b679c4fc",
   "metadata": {},
   "source": [
    "Uncomment to install the requirements for simplicits, gaussian splatting and kaolin."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ca5b9d-0166-4d24-b846-2e55fc220398",
   "metadata": {},
   "source": [
    "#### Gaussian Splatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e24505-fa1b-42ee-a938-f57b22c9c799",
   "metadata": {},
   "source": [
    "Clone and install the repo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5495ee0d-c53b-485b-86bd-c9ca0e73e8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd thirdparty\n",
    "# !git clone git@github.com:graphdeco-inria/gaussian-splatting.git gausplat --recursive\n",
    "# !cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0897a43b-03e0-4822-bf9b-ab3a2ad669e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install env gaussian-splats env from: https://github.com/graphdeco-inria/gaussian-splatting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c285c9-f047-4af8-aaaa-297f0ed67af6",
   "metadata": {},
   "source": [
    "INRIA assumes `torch 1.12.1+cu116` by default, for higher torch versions like `torch 2.0.1+cu118` --update their `environment.yaml` file to i.e:\n",
    "\n",
    "```yaml\n",
    "name: toronto_gs\n",
    "channels:\n",
    "  - pytorch\n",
    "  - nvidia\n",
    "  - conda-forge\n",
    "  - defaults\n",
    "dependencies:\n",
    "  - pytorch-cuda=11.8  # For old torch versions this is cudatoolkit=11.3\n",
    "  - plyfile=0.8.1\n",
    "  - python=3.8\n",
    "  - pip=22.3.1\n",
    "  - pytorch=2.0.1\n",
    "  - torchaudio=2.0.2\n",
    "  - torchvision=2.0.2\n",
    "  - tqdm\n",
    "  - pip:\n",
    "    - submodules/diff-gaussian-rasterization\n",
    "    - submodules/simple-knn\n",
    "```\n",
    "And then build their env:\n",
    "```bash\n",
    "# May take awhile, see the INRIA github for an alternative way\n",
    "conda env create --file environment.yml\n",
    "conda activate gaussians\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915fe3c4-773b-420b-b37d-61698480b582",
   "metadata": {},
   "source": [
    "#### simlpicits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3f835a2-2dfa-4b40-89f2-6c2a82eb0b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install libigl\n",
    "# !pip install polyscope\n",
    "# !pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22ae3a1-b100-45b1-84de-7f28b6a2d871",
   "metadata": {},
   "source": [
    "#### kaolin\n",
    "For kaolin, we need to pick the wheel with the correct torch version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45d541bf-1e41-42db-9b72-7b47a6e004b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TORCH_VERSION = 'torch-2.0.1_cu118'  # Change to yours, take care to replace hyphens, periods and underscores.\n",
    "# !pip install kaolin==0.14.0 -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/{TORCH_VERSION}.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13835d7-837a-43cb-bf4e-64498b58a080",
   "metadata": {},
   "source": [
    "*If you're not sure about your torch version, use the following:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f44f0de2-30a0-4a83-b5c6-eafca83d5cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('-- Your torch / CUDA versions are: --')\n",
    "# torch_base = !pip show torch | grep \"Version\" | cut -d' ' -f2-\n",
    "# cuda_toolkit_base = !conda list | grep pytorch-cuda\n",
    "# if len(torch_base) == 0:\n",
    "#     print('Could not infer torch version automatically, use pip or conda to look it up manually.')\n",
    "# else:\n",
    "#     torch_base = torch_base[0]\n",
    "#     print(f'TORCH: {torch_base}')\n",
    "    \n",
    "# if len(cuda_toolkit_base) == 0:\n",
    "#     print('Could not infer pytorch-cuda toolkit version automatically, use pip or conda to look it up manually.')\n",
    "#     print('In older torch versions (before 2.0.0), it may be listed under a different name: cudatookit, or together with the torch version.')\n",
    "# else:\n",
    "#     cuda_toolkit_base = cuda_toolkit_base[0].split()[1]\n",
    "#     print(f'CUDA TOOLKIT: {cuda_toolkit_base}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328c8697-a427-426b-ac0f-ce2886dc4125",
   "metadata": {},
   "source": [
    "## 0. Run the Gaussian Splatting Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac43b705-d909-4f6f-917e-f7597a23834b",
   "metadata": {},
   "source": [
    "*Uncomment the following section to train a gaussian splatting scene.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41af8eea-cc54-46b4-8083-76ff8efc77f2",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53ad4dd4-5c06-44d6-9897-7f4d5bd9bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "simplicits_working_dir = os.getcwd()\n",
    "DATA_ROOT = '/home/operel/Code/deploy/data/nerf_synthetic/lego'\n",
    "GAUSSIAN_SPLATS_REPO = f'{simplicits_working_dir}/thirdparty/gausplat'\n",
    "sys.path.append(GAUSSIAN_SPLATS_REPO) # need to make gaussplat work like a module"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fa512b-4893-4315-87e0-a0927fadbed4",
   "metadata": {},
   "source": [
    "Train a Gaussian Splatting scene, may take a few minutes.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90a9d239-755c-4ba8-89d0-9f4858abab10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(GAUSSIAN_SPLATS_REPO)\n",
    "# print(f'Changed dir to {GAUSSIAN_SPLATS_REPO}')\n",
    "\n",
    "# !python train.py -s {DATA_ROOT}\n",
    "\n",
    "# os.chdir(simplicits_working_dir)\n",
    "# print(f'Changed dir to {simplicits_working_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef09ab97-9056-4e2a-9f27-adfc8dccead0",
   "metadata": {},
   "source": [
    "#### Render & verify the scene trained correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56ba5305-22fa-4f96-82d8-49169da9b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy this from the log above\n",
    "\n",
    "# Ficus:\n",
    "# OUTPUT_FOLDER = f'{GAUSSIAN_SPLATS_REPO}/output/db198a06-1'\n",
    "\n",
    "# Lego\n",
    "OUTPUT_FOLDER = f'{GAUSSIAN_SPLATS_REPO}/output/50098c01-8'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa9ea4ac-aeb6-4c5d-bcd8-e61dc096fdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb18f05e-f8d6-41f4-9933-8a7fcc1556a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c9852f24b334103b3ab4a4446b87d17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=512, width=512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112684a147724f9994a0951d7b3ffa52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dc365800bfa4870ab64523e5024ce5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-10.353991508483887, -0.8916848301887512), description='Log Scale:', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cca7d075591a4f81b468d02a272c9c1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.0010375179117545485, 1.0), description='Opacity:', layout=Layout(width='1000px'), ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e20882a8e3740f5952cbd194768ac91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.004538313020020723, 0.7901638746261597), description='Max SH1:', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62ebab2b402642488f98cadaecc09168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.05368198826909065, 0.7654345631599426), description='Max SH2:', layout=Layout(width…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f77166017819493abc006ef730932474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-0.049128275364637375, 0.7201862335205078), description='Max SH3:', layout=Layout(widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e90e8537842340a0a4fd365eaf821cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='SH+-', layout=Layout(width='1000px'), max=2.0, readout_format='.3f', step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1113d69a73f34d9a9a1b4e94c023d944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='Rescale', layout=Layout(width='1000px'), max=10.0, min=0.001, readout_form…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from gaussian_splat_utils import load_checkpoint, try_load_kaolin_camera, GaussianSplatsRendererSetup\n",
    "\n",
    "if OUTPUT_FOLDER is None:\n",
    "    print('ERROR. No test model found. Please run the training script and set OUTPUT_FOLDER=<path/to/something/like/output/551f578e-1')    \n",
    "    \n",
    "gaussians = load_checkpoint(OUTPUT_FOLDER)\n",
    "camera = try_load_kaolin_camera(OUTPUT_FOLDER)\n",
    "renderer = GaussianSplatsRendererSetup(gaussians, camera)\n",
    "renderer.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65001cbb-40ce-448b-b728-634e3930138a",
   "metadata": {},
   "source": [
    "##### Fetch all relevant gaussian fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17110f2-c5de-42e2-a805-9d6ff4f0c581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_pts: torch.Size([342195, 3])\n",
      "gs_albedo: torch.Size([342195, 3])\n",
      "gs_opacity: torch.Size([342195, 1])\n",
      "gs_rotation: torch.Size([342195, 4])\n",
      "gs_scale: torch.Size([342195, 3])\n"
     ]
    }
   ],
   "source": [
    "gs_pts = gaussians.get_xyz\n",
    "gs_albedo = gaussians._features_dc.squeeze(1)\n",
    "gs_opacity = gaussians.get_opacity\n",
    "gs_rotation = gaussians.get_rotation\n",
    "gs_scale = gaussians.get_scaling\n",
    "for e in ['gs_pts', 'gs_albedo', 'gs_opacity', 'gs_rotation', 'gs_scale']:\n",
    "    print(f'{e}: {eval(e).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f92ad694-5f3e-4399-a3c5-944dc25fdbb8",
   "metadata": {},
   "source": [
    "##### Subsample only gaussian with opacity > 5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cb23e03-2346-40c1-8e7f-165c4e2d81f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs_pts: torch.Size([265417, 3])\n",
      "gs_albedo: torch.Size([265417, 3])\n",
      "gs_opacity: torch.Size([265417, 1])\n",
      "gs_rotation: torch.Size([265417, 4])\n",
      "gs_scale: torch.Size([265417, 3])\n"
     ]
    }
   ],
   "source": [
    "opacity_mask = (gs_opacity > 0.05).squeeze(-1)\n",
    "gs_pts = gs_pts[opacity_mask]\n",
    "gs_albedo = gs_albedo[opacity_mask]\n",
    "gs_opacity = gs_opacity[opacity_mask]\n",
    "gs_rotation = gs_rotation[opacity_mask]\n",
    "gs_scale = gs_scale[opacity_mask]\n",
    "for e in ['gs_pts', 'gs_albedo', 'gs_opacity', 'gs_rotation', 'gs_scale']:\n",
    "    print(f'{e}: {eval(e).shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe441301-963f-4931-a26f-51d9aca11ba5",
   "metadata": {},
   "source": [
    "##### Normalize albedo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0169711-9112-4bfb-83f2-fb4482dfac22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albedo normalized to range [0.0,1.0]\n"
     ]
    }
   ],
   "source": [
    "min_per_channel = gs_albedo.min(dim=0)[0]\n",
    "max_per_channel = gs_albedo.max(dim=0)[0]\n",
    "gs_albedo = (gs_albedo - min_per_channel) / (max_per_channel - min_per_channel)\n",
    "print(f'albedo normalized to range [{gs_albedo.min()},{gs_albedo.max()}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d5d28b-8d1a-4dda-bb73-deb4315cd508",
   "metadata": {},
   "source": [
    "## Hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48a522e4-cc99-445f-bb76-d6dc2422d9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General\n",
    "# object_name = \"Ficus2\"\n",
    "# training_name = \"FicusTraining2\"\n",
    "object_name = \"Lego\"\n",
    "training_name = \"LegoTraining\"\n",
    "\n",
    "show_plot=False # Use polyscope\n",
    "run_training_loop = True\n",
    "run_analysis = True\n",
    "run_simulation = True\n",
    "\n",
    "# Step 1\n",
    "object_type = \"Gaussian\"\n",
    "# yms = 1e4 # set below\n",
    "prs = 0.45\n",
    "rhos = 1000\n",
    "surf = False\n",
    "\n",
    "training_num_skinning_handles = 40 #40  # Number of skinning handles\n",
    "training_num_steps = 30000 # 30000  # Training steps\n",
    "training_num_sample_pts = 1000      # Sampled pts during training\n",
    "training_LRStart = 1e-3             # LR scheduling\n",
    "training_LREnd = 1e-4               # LR scheduling end (linear scheduling)\n",
    "training_TSamplingStdev = 1         # Magnitude of random deformations - magnituide of deformation applied per handle\n",
    "# batch_size = 10                   # Number of deformations batched at the same time\n",
    "\n",
    "# Step 5\n",
    "scene_name = 'poke_z'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0553a-3399-4eae-b31f-86c1be3159e1",
   "metadata": {},
   "source": [
    "## 1. SetupObject: Create the object.\n",
    "```json\n",
    "    a. Custom function per object with customizable post-processing for each object.\n",
    "    b. Can convert to a simplicit from a SDF, pointcloud, surface mesh, tetmesh\n",
    "    c. The object structure is a json of properties: \n",
    "    {   \"Name\":string, \"Dim\":scalar 2 or 3,\n",
    "        \"BoundingBoxSamplePts\": u x dim np.array,\n",
    "        \"BoundingBoxSignedDists\": u x 1 np.array,\n",
    "        \"ObjectSamplePts\": n x dim np.array,\n",
    "        \"ObjectSampleSignedDists\": n x 1 np.array,\n",
    "        \"ObjectYMs\": n x 1 np.array,\n",
    "        \"ObjectPRs\": n x 1 np.arry,\n",
    "        \"ObjectRho\": n x 1 np.array,\n",
    "        \"ObjectColors\": n x 4 np.array of RGBA,\n",
    "        \"ObjectVol\": scalar, \"SurfV\": v x dim np.array/None, \"SurfF\", f x dim+1 np.array/None, \"MarchingCubesRes\": scalar grid res/-1\n",
    "    }\n",
    "    d. Writes the object to the a binary file in folder called `\"<Name>/<Name>-object.json\"`\n",
    "    e. Also writes an editable json file in the folder called `\"<Name>/<Name>-training-settings.json\"` which has properties:\n",
    "        {\"Dim\": scalar 2 or 3, \"NumHandles\":scalar, \"NumLayers\":scalar, \"LayerWidth\":scalar, \"ActivationFunc\": string (\"ELU\" or \"Siren\"), \n",
    "         \"NumTrainingSteps\": int, \"NumSamplePts\": int, \"LRStart\": scalar, \"LREnd\": scalar,\n",
    "         \"TSamplingStdev\": scalar, \"TBatchSize\": int, \n",
    "         \"LossCurveMovingAvgWindow\": scalar, \"SaveHandleIts\": scalar, \"SaveSampleIts\" scalar, \"NumSamplesToView\": scalar\n",
    "        }\n",
    "    f. Run by doing `\"python 1-SetupObject.py\"`\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d69995-cd9a-4216-8f13-5a3ac2a52c83",
   "metadata": {},
   "source": [
    "#### Gaussians -> Segmented Points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67634f0a-f36c-4270-9e90-2215ef1ea1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "segment_colors = np.array([\n",
    "    [1.0, 0.0, 0.0],  # 0: Red\n",
    "    [0.0, 1.0, 0.0],  # 1: Green\n",
    "    [1.0, 0.0, 1.0],  # 2: Pink \n",
    "    [0.0, 0.0, 1.0],  # 3: Blue\n",
    "    [1.0, 1.0, 0.0],  # 4: Yellow\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73266a52-5326-4dec-9fab-923ee3c1a9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5015f68d43aa4b52a43a0ba24b759117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=512, width=512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751037e81b844e34bea448c894f08cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ec4024ab47c4b848b1fabf8b1d21c8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-10.353991508483887, -1.5763815641403198), description='Log Scale:', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3c3e534aad4097963437a867060ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.05000133812427521, 1.0), description='Opacity:', layout=Layout(width='1000px'), max=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aeec0088c612470686350c3f0dd6534b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-4.538313078228384e-06, 0.0007901639328338206), description='Max SH1:', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b61ac7065924667a8cb96669160c26d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-5.368198981159367e-05, 0.0007654345827177167), description='Max SH2:', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d59a31645ee457e88212ba3d0657a1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-4.912827716907486e-05, 0.0006377023528330028), description='Max SH3:', layout=Layout(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b964f8c2e5a467494698ce3fce49b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='SH+-', layout=Layout(width='1000px'), max=2.0, readout_format='.3f', step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6412fce6f624d52a0559ce56c80a36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='Rescale', layout=Layout(width='1000px'), max=10.0, min=0.001, readout_form…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import copy\n",
    "import torch\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "segmented_gaussians = copy.deepcopy(gaussians)\n",
    "\n",
    "segmentation_features = np.concatenate([\n",
    "    gs_pts.detach().cpu().numpy()[:,1:3],   # y-z pos\n",
    "    gs_albedo.detach().cpu().numpy()        # base color\n",
    "], axis=1)\n",
    "\n",
    "kmeans = KMeans(n_clusters=5, random_state=0, n_init=\"auto\").fit(segmentation_features)\n",
    "segmented_gaussians._features_dc = torch.from_numpy(segment_colors[kmeans.labels_]).cuda().float().unsqueeze(1)\n",
    "\n",
    "# kmeans.cluster_centers_\n",
    "\n",
    "segmented_gaussians._xyz = segmented_gaussians._xyz[opacity_mask]\n",
    "segmented_gaussians._features_rest = segmented_gaussians._features_rest[opacity_mask] * 1e-3  # Turn off directional light\n",
    "segmented_gaussians._scaling = segmented_gaussians._scaling[opacity_mask]\n",
    "segmented_gaussians._rotation = segmented_gaussians._rotation[opacity_mask]\n",
    "segmented_gaussians._opacity = segmented_gaussians._opacity[opacity_mask]\n",
    "renderer = GaussianSplatsRendererSetup(segmented_gaussians, camera)\n",
    "renderer.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "541a9424-ce61-431d-b2f6-94f5c669fb6d",
   "metadata": {},
   "source": [
    "#### Create the object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2e105726-363a-46bf-ba61-450e44b03545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Segments --\n",
    "# 0: Red --> Branches\n",
    "# 1: Green --> Branches\n",
    "# 2: Pink --> Pot + Trunk Base\n",
    "# 3: Blue --> Branches\n",
    "# 4: Yellow --> Trunk\n",
    "young_modulus = np.array([ # Stiffness by segment\n",
    "    1e4,\n",
    "    1e4,\n",
    "    1e4*0.95,\n",
    "    1e4,\n",
    "    1e4\n",
    "])\n",
    "gs_YMs = young_modulus[kmeans.labels_]\n",
    "gs_PRs = 0.45*np.ones_like(gs_YMs)\n",
    "gs_Rho = 100*np.ones_like(gs_YMs)\n",
    "\n",
    "\n",
    "np_object = {\n",
    "    \"Name\": object_name, \n",
    "    \"Dim\": 3, \n",
    "    \"BoundingBoxSamplePts\": None, \n",
    "    \"BoundingBoxSignedDists\": None,\n",
    "    \"ObjectSamplePts\": gs_pts.cpu().detach().numpy(), \n",
    "    \"ObjectSampleColors\" : gs_albedo.cpu().detach().numpy(),\n",
    "    \"ObjectYMs\": gs_YMs, \n",
    "    \"ObjectPRs\": gs_PRs, \n",
    "    \"ObjectRho\": gs_Rho, \n",
    "    \"ObjectColors\": None,\n",
    "    \"ObjectVol\": 1, \n",
    "    \"SurfV\": None, \n",
    "    \"SurfF\": None, \n",
    "    \"MarchingCubesRes\": -1\n",
    "}\n",
    "\n",
    "# NeRF Ficus also rotates the object, which we omit here:\n",
    "# Omitted: rotate_points_x(torch.tensor(nerf_pts, device=device, dtype=torch.float32), -90, axis = 0).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea287a7-fe2d-4477-a1ca-eeee93dd2191",
   "metadata": {},
   "source": [
    "##### Generates training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "609195d1-3bdc-43a2-841d-7a54fd5b8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'NumHandles': 40,\n",
       " 'NumLayers': 10,\n",
       " 'LayerWidth': 64,\n",
       " 'ActivationFunc': 'ELU',\n",
       " 'NumTrainingSteps': 30000,\n",
       " 'NumSamplePts': 1000,\n",
       " 'LRStart': 0.001,\n",
       " 'LREnd': 0.0001,\n",
       " 'TSamplingStdev': 1,\n",
       " 'TBatchSize': 10,\n",
       " 'LossCurveMovingAvgWindow': 100,\n",
       " 'SaveHandleIts': 1000,\n",
       " 'SaveSampleIts': 20000,\n",
       " 'NumSamplesToView': 5,\n",
       " 'Timeit': True}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from SetupObject_1 import getDefaultTrainingSettings\n",
    "training_dict = getDefaultTrainingSettings()\n",
    "training_dict[\"NumHandles\"] = training_num_skinning_handles\n",
    "training_dict[\"NumTrainingSteps\"] = training_num_steps\n",
    "training_dict[\"NumSamplePts\"] = training_num_sample_pts\n",
    "training_dict[\"LRStart\"] = training_LRStart\n",
    "training_dict[\"LREnd\"] = training_LREnd\n",
    "training_dict[\"TSamplingStdev\"] = training_TSamplingStdev\n",
    "training_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97f305-f9e2-42c2-81c6-6a61ddbf85de",
   "metadata": {},
   "source": [
    "#### Save object and training settings to disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6649a814-5961-4ebf-9a10-589fdd318e24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object saved to: /home/operel/Code/deploy/simplicits/Lego/Lego-object\n",
      "Training settings saved to: /home/operel/Code/deploy/simplicits/Lego/Lego-training-settings.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "sim_obj_name = object_name\n",
    "\n",
    "if not os.path.exists(sim_obj_name):\n",
    "    os.makedirs(sim_obj_name)\n",
    "torch.save(np_object, sim_obj_name + \"/\" +sim_obj_name+\"-\"+\"object\")\n",
    "print(f'Object saved to: {os.getcwd() + \"/\" + sim_obj_name + \"/\" +sim_obj_name+\"-\"+\"object\"}')\n",
    "\n",
    "if not os.path.exists(sim_obj_name+\"/\"+sim_obj_name+\"-training-settings.json\"):\n",
    "    \n",
    "    json_object = json.dumps(training_dict, indent=4)\n",
    "    # Writing to sample.json\n",
    "    with open(sim_obj_name+\"/\"+sim_obj_name+\"-training-settings.json\", \"w\") as outfile:\n",
    "        outfile.write(json_object)\n",
    "print(f'Training settings saved to: {os.getcwd() + \"/\" + sim_obj_name+\"/\"+sim_obj_name+\"-training-settings.json\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4f45de-7cae-449b-9dcb-bf23ecc85242",
   "metadata": {},
   "source": [
    "## 2. SetupTraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa797bb2-13ea-4ff6-a164-00d3f3efad72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import SetupTraining_2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import random, os, sys\n",
    "from SimplicitHelpers import *\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fbd5bc0-965e-4819-b7a0-eadd161dac70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b5b9a34a-e0cd-4784-829e-1232c23274bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LegoTraining\n"
     ]
    }
   ],
   "source": [
    "fname = f\"{object_name}/{object_name}\"\n",
    "np_object = torch.load(fname+\"-object\")\n",
    "print(training_name)\n",
    "\n",
    "# Opening JSON file with training settings\n",
    "with open(fname+\"-training-settings.json\", 'r') as openfile:\n",
    "    training_settings = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ed609bf-2bde-4934-a4b3-8767c489322f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--List of learned params:--\n",
      "linear_relu_stack.0.weight torch.Size([64, 3])\n",
      "linear_relu_stack.0.bias torch.Size([64])\n",
      "linear_relu_stack.2.weight torch.Size([64, 64])\n",
      "linear_relu_stack.2.bias torch.Size([64])\n",
      "linear_relu_stack.4.weight torch.Size([64, 64])\n",
      "linear_relu_stack.4.bias torch.Size([64])\n",
      "linear_relu_stack.6.weight torch.Size([64, 64])\n",
      "linear_relu_stack.6.bias torch.Size([64])\n",
      "linear_relu_stack.8.weight torch.Size([64, 64])\n",
      "linear_relu_stack.8.bias torch.Size([64])\n",
      "linear_relu_stack.10.weight torch.Size([64, 64])\n",
      "linear_relu_stack.10.bias torch.Size([64])\n",
      "linear_relu_stack.12.weight torch.Size([64, 64])\n",
      "linear_relu_stack.12.bias torch.Size([64])\n",
      "linear_relu_stack.14.weight torch.Size([64, 64])\n",
      "linear_relu_stack.14.bias torch.Size([64])\n",
      "linear_relu_stack.16.weight torch.Size([64, 64])\n",
      "linear_relu_stack.16.bias torch.Size([64])\n",
      "linear_relu_stack.18.weight torch.Size([64, 64])\n",
      "linear_relu_stack.18.bias torch.Size([64])\n",
      "linear_relu_stack.20.weight torch.Size([64, 64])\n",
      "linear_relu_stack.20.bias torch.Size([64])\n",
      "linear_relu_stack.22.weight torch.Size([40, 64])\n",
      "linear_relu_stack.22.bias torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "Handles_pre = HandleModels(training_settings[\"NumHandles\"], training_settings[\"NumLayers\"], training_settings[\"LayerWidth\"], training_settings[\"ActivationFunc\"], np_object[\"Dim\"], training_settings[\"LRStart\"])\n",
    "Handles_post = HandleModels(training_settings[\"NumHandles\"], training_settings[\"NumLayers\"], training_settings[\"LayerWidth\"], training_settings[\"ActivationFunc\"], np_object[\"Dim\"], training_settings[\"LRStart\"])\n",
    "\n",
    "## Moving stuff to GPU\n",
    "Handles_post.to_device(device)\n",
    "Handles_pre.to_device(device)\n",
    "Handles_pre.eval()\n",
    "\n",
    "t_O = torch.tensor(np_object[\"ObjectSamplePts\"][:,0:3]).to(device)\n",
    "\n",
    "print('--List of learned params:--')\n",
    "for nnnn, pppp in Handles_post.model.named_parameters():\n",
    "    print(nnnn, pppp.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e86fc8c7-1c73-4c5b-b8dd-ec789ed458af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Architecture:--\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'num_handles': 40,\n",
       " 'num_layers': 10,\n",
       " 'layer_width': 64,\n",
       " 'activation_func': 'ELU',\n",
       " 'lr_start': 0.001,\n",
       " 'model': StrandleWeightsMLP(\n",
       "   (linear_relu_stack): Sequential(\n",
       "     (0): Linear(in_features=3, out_features=64, bias=True)\n",
       "     (1): ELU(alpha=1.0)\n",
       "     (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (3): ELU(alpha=1.0)\n",
       "     (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (5): ELU(alpha=1.0)\n",
       "     (6): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (7): ELU(alpha=1.0)\n",
       "     (8): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (9): ELU(alpha=1.0)\n",
       "     (10): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (11): ELU(alpha=1.0)\n",
       "     (12): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (13): ELU(alpha=1.0)\n",
       "     (14): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (15): ELU(alpha=1.0)\n",
       "     (16): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (17): ELU(alpha=1.0)\n",
       "     (18): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (19): ELU(alpha=1.0)\n",
       "     (20): Linear(in_features=64, out_features=64, bias=True)\n",
       "     (21): ELU(alpha=1.0)\n",
       "     (22): Linear(in_features=64, out_features=40, bias=True)\n",
       "   )\n",
       " ),\n",
       " 'optimizers': Adam (\n",
       " Parameter Group 0\n",
       "     amsgrad: False\n",
       "     betas: (0.9, 0.999)\n",
       "     capturable: False\n",
       "     differentiable: False\n",
       "     eps: 1e-08\n",
       "     foreach: None\n",
       "     fused: None\n",
       "     lr: 0.001\n",
       "     maximize: False\n",
       "     weight_decay: 0\n",
       " ),\n",
       " 'device': 'cuda'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np_W0, np_X0, np_G0 = test(Handles_post, t_O, int(t_O.shape[0]/10))\n",
    "\n",
    "print('--Architecture:--')\n",
    "Handles_pre.__dict__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc74697-3f05-45ed-a178-506b6b143e0b",
   "metadata": {},
   "source": [
    "#### Initial Skinning Weights Plot\n",
    "Simulating those would give garbage results, but you can observe what they look like.\n",
    "\n",
    "The weights are initialized inside `SimplicitHelpers` and are initialized to completely random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c94e3967-1eba-4bb6-b96a-5f9037f5a691",
   "metadata": {},
   "outputs": [],
   "source": [
    "if show_plot:\n",
    "    plot_handle_regions(np_X0, np_W0, \"Pre Training Handle Weights\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14face63-053b-465a-80c0-8f251639d6bf",
   "metadata": {},
   "source": [
    "The following visualization shows the initial Young Modulu values before training (pink).\n",
    "In some cases they are uniform, for some of the biologically inspired examples, that may vary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b6a90cd-3db5-412b-b080-4ac2562862dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if show_plot:\n",
    "#     plot_implicit(np_object[\"ObjectSamplePts\"], np_object[\"ObjectYMs\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b6109987-f59b-44af-bf34-d1da949ee674",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving setup for Lego/LegoTraining-training\n",
      "Training settings saved to: /home/operel/Code/deploy/simplicits/Lego/LegoTraining-training/training-settings.json\n",
      "Handles_post saved to: /home/operel/Code/deploy/simplicits/Lego/LegoTraining-training/losses\n",
      "Handles_post saved to: /home/operel/Code/deploy/simplicits/Lego/LegoTraining-training/Handles_post\n",
      "Handles_post saved to: /home/operel/Code/deploy/simplicits/Lego/LegoTraining-training/Handles_pre\n"
     ]
    }
   ],
   "source": [
    "print(\"Saving setup for \" + object_name+\"/\"+training_name+\"-training\")\n",
    "if not os.path.exists(object_name+\"/\"+training_name+\"-training\"):\n",
    "    os.makedirs(object_name+\"/\"+training_name+\"-training\")\n",
    "\n",
    "# rewrite over training settings, and losses and handle state (final)\n",
    "with open(object_name+\"/\"+training_name+\"-training/training-settings.json\", 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_settings, f, ensure_ascii=False, indent=4)\n",
    "torch.save(Handles_post, object_name+\"/\"+training_name+\"-training\"+\"/losses\")\n",
    "torch.save(Handles_post, object_name+\"/\"+training_name+\"-training\"+\"/Handles_post\")\n",
    "torch.save(Handles_pre, object_name+\"/\"+training_name+\"-training\"+\"/Handles_pre\")\n",
    "\n",
    "print(f'Training settings saved to: {os.getcwd() + \"/\" + object_name+\"/\"+training_name+\"-training/training-settings.json\"}')\n",
    "print(f'Handles_post saved to: {os.getcwd() + \"/\" + object_name+\"/\"+training_name+\"-training\"+\"/losses\"}')\n",
    "print(f'Handles_post saved to: {os.getcwd() + \"/\" + object_name+\"/\"+training_name+\"-training\"+\"/Handles_post\"}')\n",
    "print(f'Handles_post saved to: {os.getcwd() + \"/\" + object_name+\"/\"+training_name+\"-training\"+\"/Handles_pre\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4dbf8ed-31fe-4ee9-8e01-aef9b9098e9a",
   "metadata": {},
   "source": [
    "## 3. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83a30184-b0e6-4f16-b5fb-6faab46228fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_and_training_dir = object_name+\"/\"+training_name+\"-training\"\n",
    "Handles_post.to_device(device)\n",
    "\n",
    "t_O = torch.tensor(np_object[\"ObjectSamplePts\"][:,0:3]).to(device)\n",
    "t_YMs = torch.tensor(np_object[\"ObjectYMs\"]).unsqueeze(-1).to(device)\n",
    "t_PRs = torch.tensor(np_object[\"ObjectPRs\"]).unsqueeze(-1).to(device)\n",
    "# Use torch.where to find indices where the value is equal to 2e4\n",
    "ym_min_val = t_YMs.min()\n",
    "ym_max_val = t_YMs.max()\n",
    "stiffer_indices = torch.where(t_YMs == ym_max_val)[0]\n",
    "\n",
    "TOTAL_TRAINING_STEPS = int(training_settings[\"NumTrainingSteps\"])\n",
    "\n",
    "ENERGY_INTERP_LINSPACE = np.linspace(0, 1, TOTAL_TRAINING_STEPS, endpoint=False)\n",
    "LR_INTERP_LINSPCE = np.linspace(float(training_settings[\"LRStart\"]), float(training_settings[\"LREnd\"]), TOTAL_TRAINING_STEPS, endpoint=True)\n",
    "YM_INTERP_LINSPACE = np.linspace(ym_max_val.cpu().detach().numpy(), ym_max_val.cpu().detach().numpy(), TOTAL_TRAINING_STEPS, endpoint=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bbcac2-db53-4f69-a62e-fb38a74f1360",
   "metadata": {},
   "source": [
    "#### Test a single batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "61d918a2-16b1-40bb-b693-836519b15ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch / NumHandles / Affine Transform Matrix\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 40, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_num = 0\n",
    "batch = getBatchOfTs(Handles_post.num_handles, int(training_settings[\"TBatchSize\"]), step_num)\n",
    "batch = batch.float()*float(training_settings[\"TSamplingStdev\"])\n",
    "print('Batch / NumHandles / Affine Transform Matrix')\n",
    "batch.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60384145-d99d-4506-8901-8eb7876129b4",
   "metadata": {},
   "source": [
    "#### Test a single iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b9e662-93a8-4ee3-8a19-62494d457cbc",
   "metadata": {},
   "source": [
    "Follows `train()` in SimplicitsHelper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5cfacf5a-7532-4e43-85eb-9738da4eaa20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O: ObjectSamplePts\n",
      "torch.Size([265417, 3])\n",
      "YoungsMod:\n",
      "torch.Size([265417, 1])\n",
      "PRs:\n",
      "torch.Size([265417, 1])\n",
      "Handles:\n",
      "<class 'SimplicitHelpers.HandleModels'>\n"
     ]
    }
   ],
   "source": [
    "Handles = Handles_post\n",
    "O = t_O\n",
    "YoungsMod = t_YMs\n",
    "PRs = t_PRs\n",
    "t_batchTs = batch.to(device)\n",
    "\n",
    "print('O: ObjectSamplePts')\n",
    "print(O.shape)\n",
    "print('YoungsMod:')\n",
    "print(YoungsMod.shape)\n",
    "print('PRs:')\n",
    "print(PRs.shape)\n",
    "print('Handles:')\n",
    "print(f'{type(Handles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eeb0d362-0606-4f16-b3bf-b2bc0102f2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Randomizing (1000,) batch indices between 0..265417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([  7016, 108309, 120881,  65018, 140864,  25280,  91825, 228412, 172165,\n",
       "        211254])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Handles.train()\n",
    "print(f'Randomizing {(int(training_settings[\"NumSamplePts\"]),)} batch indices between 0..{t_O.shape[0]}')\n",
    "random_batch_indices = torch.randint(low=0, high=int(t_O.shape[0]), size=(int(training_settings[\"NumSamplePts\"]),))\n",
    "random_batch_indices[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23367592-520f-4286-95ef-5c1befc98439",
   "metadata": {},
   "source": [
    "A single training step applies a random deformation on the points and computes 2 loss functions:\n",
    "1. Minimizes the potential energy (`E_pot`)\n",
    "2. The handles should be orthogonal\n",
    "\n",
    "The lambda weights for balancing the losses are fixed and were evaluated empirically. Should fit most object and normally shouldn't be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2365c96-83e0-461e-b1d5-fe85f2e2b952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X0 = O[random_batch_indices].float().to(device)\n",
    "# X0.requires_grad = True\n",
    "\n",
    "# YMs = YoungsMod[random_batch_indices,:].float().to(device)\n",
    "# poisson = PRs[random_batch_indices,:].float().to(device)\n",
    "# mus = YMs/(2*(1+poisson)) #shead modulus\n",
    "# lams = YMs*poisson/((1+poisson)*(1-2*poisson)) #\n",
    "# W = Handles.getAllWeightsSoftmax(X0)\n",
    "\n",
    "# # Backpropagation\n",
    "# Handles.optimizers_zero_grad()\n",
    "\n",
    "# interp_val = ENERGY_INTERP_LINSPACE[step_num]\n",
    "\n",
    "# loss1, loss2 = loss_fcn(W, X0, mus, lams, batchTs, Handles, interp_val)\n",
    "# loss = loss1 + loss2\n",
    "# loss.backward()\n",
    "\n",
    "# # Backpropagation\n",
    "# Handles.optimizers_step()\n",
    "# Handles.updateLR(LR_INTERP_LINSPCE[step])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d743cd87-0400-46c0-9839-bfe0ad67ae32",
   "metadata": {},
   "source": [
    "#### The complete training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4a5330fe-bea6-4607-801b-f07fb43ff363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import random, os, sys\n",
    "import json\n",
    "from SimplicitHelpers import *\n",
    "from trainer import Trainer\n",
    "\n",
    "trainer = Trainer(object_name, training_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9b3da4ec-85a3-4862-9d0e-beed752afbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start Training\n",
      "Step:  100 Loss: 24422.236360549927  > l1:  8.761751174926758  > l2:  24413.474609375\n",
      "Step:  200 Loss: 24363.763038635254  > l1:  7.069679260253906  > l2:  24356.693359375\n",
      "Step:  300 Loss: 24360.09476995468  > l1:  6.7236762046813965  > l2:  24353.37109375\n",
      "Step:  400 Loss: 24350.43064546585  > l1:  4.83689546585083  > l2:  24345.59375\n",
      "Step:  500 Loss: 24338.567365169525  > l1:  6.7822089195251465  > l2:  24331.78515625\n",
      "Step:  600 Loss: 24276.880823135376  > l1:  8.234338760375977  > l2:  24268.646484375\n",
      "Step:  700 Loss: 23844.647611618042  > l1:  25.801908493041992  > l2:  23818.845703125\n",
      "Step:  800 Loss: 23775.709255218506  > l1:  35.37136459350586  > l2:  23740.337890625\n",
      "Step:  900 Loss: 23753.089515686035  > l1:  13.880531311035156  > l2:  23739.208984375\n",
      "Step:  1000 Loss: 23767.00373840332  > l1:  34.47053527832031  > l2:  23732.533203125\n",
      "Step:  1100 Loss: 23745.994342803955  > l1:  23.172077178955078  > l2:  23722.822265625\n",
      "Step:  1200 Loss: 23730.139974594116  > l1:  28.77669334411621  > l2:  23701.36328125\n",
      "Step:  1300 Loss: 23642.700170516968  > l1:  20.916967391967773  > l2:  23621.783203125\n",
      "Step:  1400 Loss: 23216.55361557007  > l1:  55.90908432006836  > l2:  23160.64453125\n",
      "Step:  1500 Loss: 23167.63796234131  > l1:  34.032493591308594  > l2:  23133.60546875\n",
      "Step:  1600 Loss: 23162.65665435791  > l1:  36.146888732910156  > l2:  23126.509765625\n",
      "Step:  1700 Loss: 23154.37085533142  > l1:  30.4118709564209  > l2:  23123.958984375\n",
      "Step:  1800 Loss: 23183.76396560669  > l1:  55.77959060668945  > l2:  23127.984375\n",
      "Step:  1900 Loss: 23175.499866485596  > l1:  46.6658821105957  > l2:  23128.833984375\n",
      "Step:  2000 Loss: 23167.95887374878  > l1:  46.3241081237793  > l2:  23121.634765625\n",
      "Step:  2100 Loss: 23171.695667266846  > l1:  51.4085578918457  > l2:  23120.287109375\n",
      "Step:  2200 Loss: 23164.99729537964  > l1:  50.56956100463867  > l2:  23114.427734375\n",
      "Step:  2300 Loss: 23165.65298461914  > l1:  69.45571899414062  > l2:  23096.197265625\n",
      "Step:  2400 Loss: 23018.0565032959  > l1:  90.49009704589844  > l2:  22927.56640625\n",
      "Step:  2500 Loss: 22606.753982543945  > l1:  101.10359191894531  > l2:  22505.650390625\n",
      "Step:  2600 Loss: 22571.8680267334  > l1:  64.30943298339844  > l2:  22507.55859375\n",
      "Step:  2700 Loss: 22631.11163330078  > l1:  115.71905517578125  > l2:  22515.392578125\n",
      "Step:  2800 Loss: 22601.04490661621  > l1:  95.56639099121094  > l2:  22505.478515625\n",
      "Step:  2900 Loss: 22571.29222869873  > l1:  69.82347869873047  > l2:  22501.46875\n",
      "Step:  3000 Loss: 22596.634757995605  > l1:  93.61327362060547  > l2:  22503.021484375\n",
      "Step:  3100 Loss: 22597.31671142578  > l1:  88.40069580078125  > l2:  22508.916015625\n",
      "Step:  3200 Loss: 22617.917068481445  > l1:  110.30964660644531  > l2:  22507.607421875\n",
      "Step:  3300 Loss: 22625.88422393799  > l1:  91.58930206298828  > l2:  22534.294921875\n",
      "Step:  3400 Loss: 22632.079849243164  > l1:  106.61500549316406  > l2:  22525.46484375\n",
      "Step:  3500 Loss: 22610.185745239258  > l1:  107.00215148925781  > l2:  22503.18359375\n",
      "Step:  3600 Loss: 22582.96809387207  > l1:  80.39387512207031  > l2:  22502.57421875\n",
      "Step:  3700 Loss: 22611.426963806152  > l1:  108.84883880615234  > l2:  22502.578125\n",
      "Step:  3800 Loss: 22580.96706390381  > l1:  75.7561264038086  > l2:  22505.2109375\n",
      "Step:  3900 Loss: 22617.523071289062  > l1:  105.8121337890625  > l2:  22511.7109375\n",
      "Step:  4000 Loss: 22569.0365524292  > l1:  64.53264617919922  > l2:  22504.50390625\n",
      "Step:  4100 Loss: 22600.034675598145  > l1:  85.47998809814453  > l2:  22514.5546875\n",
      "Step:  4200 Loss: 22594.09673309326  > l1:  95.62407684326172  > l2:  22498.47265625\n",
      "Step:  4300 Loss: 22598.972373962402  > l1:  104.25557708740234  > l2:  22494.716796875\n",
      "Step:  4400 Loss: 22572.773124694824  > l1:  78.71257781982422  > l2:  22494.060546875\n",
      "Step:  4500 Loss: 22562.150871276855  > l1:  88.31493377685547  > l2:  22473.8359375\n",
      "Step:  4600 Loss: 22198.84597015381  > l1:  115.3733139038086  > l2:  22083.47265625\n",
      "Step:  4700 Loss: 21991.632530212402  > l1:  108.95088958740234  > l2:  21882.681640625\n",
      "Step:  4800 Loss: 21977.233291625977  > l1:  105.70594787597656  > l2:  21871.52734375\n",
      "Step:  4900 Loss: 21953.797119140625  > l1:  138.310791015625  > l2:  21815.486328125\n",
      "Step:  5000 Loss: 21439.458786010742  > l1:  168.9783172607422  > l2:  21270.48046875\n",
      "Step:  5100 Loss: 21464.397506713867  > l1:  158.2197723388672  > l2:  21306.177734375\n",
      "Step:  5200 Loss: 21450.878479003906  > l1:  157.49176025390625  > l2:  21293.38671875\n",
      "Step:  5300 Loss: 21405.09603881836  > l1:  134.10189819335938  > l2:  21270.994140625\n",
      "Step:  5400 Loss: 21416.15623474121  > l1:  152.07029724121094  > l2:  21264.0859375\n",
      "Step:  5500 Loss: 21389.471488952637  > l1:  118.06328582763672  > l2:  21271.408203125\n",
      "Step:  5600 Loss: 20902.926345825195  > l1:  187.1001739501953  > l2:  20715.826171875\n",
      "Step:  5700 Loss: 20899.850341796875  > l1:  234.526123046875  > l2:  20665.32421875\n",
      "Step:  5800 Loss: 20307.428619384766  > l1:  227.26651000976562  > l2:  20080.162109375\n",
      "Step:  5900 Loss: 20381.39794921875  > l1:  259.86279296875  > l2:  20121.53515625\n",
      "Step:  6000 Loss: 20339.324676513672  > l1:  291.1215515136719  > l2:  20048.203125\n",
      "Step:  6100 Loss: 20291.966430664062  > l1:  261.4820556640625  > l2:  20030.484375\n",
      "Step:  6200 Loss: 19959.912536621094  > l1:  357.31292724609375  > l2:  19602.599609375\n",
      "Step:  6300 Loss: 19743.52572631836  > l1:  276.2112731933594  > l2:  19467.314453125\n",
      "Step:  6400 Loss: 19480.57699584961  > l1:  363.1336364746094  > l2:  19117.443359375\n",
      "Step:  6500 Loss: 19220.23223876953  > l1:  442.55645751953125  > l2:  18777.67578125\n",
      "Step:  6600 Loss: 18879.893951416016  > l1:  491.6498107910156  > l2:  18388.244140625\n",
      "Step:  6700 Loss: 18495.41470336914  > l1:  470.5279846191406  > l2:  18024.88671875\n",
      "Step:  6800 Loss: 17754.785888671875  > l1:  685.668701171875  > l2:  17069.1171875\n",
      "Step:  6900 Loss: 17223.68438720703  > l1:  629.9519653320312  > l2:  16593.732421875\n",
      "Step:  7000 Loss: 16781.8310546875  > l1:  819.875  > l2:  15961.9560546875\n",
      "Step:  7100 Loss: 16087.066284179688  > l1:  754.0281982421875  > l2:  15333.0380859375\n",
      "Step:  7200 Loss: 15674.094543457031  > l1:  951.2556762695312  > l2:  14722.8388671875\n",
      "Step:  7300 Loss: 15485.428161621094  > l1:  958.8041381835938  > l2:  14526.6240234375\n",
      "Step:  7400 Loss: 15351.457641601562  > l1:  1147.5679931640625  > l2:  14203.8896484375\n",
      "Step:  7500 Loss: 14634.928649902344  > l1:  1012.5546264648438  > l2:  13622.3740234375\n",
      "Step:  7600 Loss: 14495.427001953125  > l1:  1285.333251953125  > l2:  13210.09375\n",
      "Step:  7700 Loss: 14485.311401367188  > l1:  1487.0692138671875  > l2:  12998.2421875\n",
      "Step:  7800 Loss: 13691.1953125  > l1:  1365.484375  > l2:  12325.7109375\n",
      "Step:  7900 Loss: 13456.05859375  > l1:  1545.0048828125  > l2:  11911.0537109375\n",
      "Step:  8000 Loss: 13059.8154296875  > l1:  1441.888671875  > l2:  11617.9267578125\n",
      "Step:  8100 Loss: 12611.758178710938  > l1:  1531.9505615234375  > l2:  11079.8076171875\n",
      "Step:  8200 Loss: 12227.234497070312  > l1:  1500.7608642578125  > l2:  10726.4736328125\n",
      "Step:  8300 Loss: 12338.394165039062  > l1:  1707.6695556640625  > l2:  10630.724609375\n",
      "Step:  8400 Loss: 12232.045776367188  > l1:  1816.7156982421875  > l2:  10415.330078125\n",
      "Step:  8500 Loss: 11812.4521484375  > l1:  1905.2177734375  > l2:  9907.234375\n",
      "Step:  8600 Loss: 11370.394409179688  > l1:  1843.5770263671875  > l2:  9526.8173828125\n",
      "Step:  8700 Loss: 11544.69384765625  > l1:  2141.42919921875  > l2:  9403.2646484375\n",
      "Step:  8800 Loss: 10864.535766601562  > l1:  1987.5797119140625  > l2:  8876.9560546875\n",
      "Step:  8900 Loss: 10693.14599609375  > l1:  2077.14599609375  > l2:  8616.0\n",
      "Step:  9000 Loss: 10251.297485351562  > l1:  1911.7877197265625  > l2:  8339.509765625\n",
      "Step:  9100 Loss: 9938.951171875  > l1:  2062.42626953125  > l2:  7876.52490234375\n",
      "Step:  9200 Loss: 10005.912353515625  > l1:  2266.478271484375  > l2:  7739.43408203125\n",
      "Step:  9300 Loss: 9815.486572265625  > l1:  2332.507568359375  > l2:  7482.97900390625\n",
      "Step:  9400 Loss: 9210.988037109375  > l1:  2157.758544921875  > l2:  7053.2294921875\n",
      "Step:  9500 Loss: 9652.463623046875  > l1:  2471.806396484375  > l2:  7180.6572265625\n",
      "Step:  9600 Loss: 8771.139282226562  > l1:  2016.2593994140625  > l2:  6754.8798828125\n",
      "Step:  9700 Loss: 8976.671630859375  > l1:  2195.009521484375  > l2:  6781.662109375\n",
      "Step:  9800 Loss: 9307.85400390625  > l1:  2584.31201171875  > l2:  6723.5419921875\n",
      "Step:  9900 Loss: 9177.0517578125  > l1:  2532.57177734375  > l2:  6644.47998046875\n",
      "Step:  10000 Loss: 8764.362060546875  > l1:  2536.683837890625  > l2:  6227.67822265625\n",
      "Step:  10100 Loss: 8629.910400390625  > l1:  2413.183837890625  > l2:  6216.7265625\n",
      "Step:  10200 Loss: 8861.30615234375  > l1:  2665.3046875  > l2:  6196.00146484375\n",
      "Step:  10300 Loss: 8653.140380859375  > l1:  2438.849365234375  > l2:  6214.291015625\n",
      "Step:  10400 Loss: 7927.14892578125  > l1:  2253.30078125  > l2:  5673.84814453125\n",
      "Step:  10500 Loss: 8400.116943359375  > l1:  2220.494873046875  > l2:  6179.6220703125\n",
      "Step:  10600 Loss: 8019.915771484375  > l1:  2389.800537109375  > l2:  5630.115234375\n",
      "Step:  10700 Loss: 8140.30859375  > l1:  2487.30419921875  > l2:  5653.00439453125\n",
      "Step:  10800 Loss: 8272.558349609375  > l1:  2554.364990234375  > l2:  5718.193359375\n",
      "Step:  10900 Loss: 7943.0048828125  > l1:  2708.0068359375  > l2:  5234.998046875\n",
      "Step:  11000 Loss: 7963.6484375  > l1:  2954.36328125  > l2:  5009.28515625\n",
      "Step:  11100 Loss: 7318.10302734375  > l1:  2483.59716796875  > l2:  4834.505859375\n",
      "Step:  11200 Loss: 7471.627685546875  > l1:  2722.381591796875  > l2:  4749.24609375\n",
      "Step:  11300 Loss: 7932.007080078125  > l1:  3159.596435546875  > l2:  4772.41064453125\n",
      "Step:  11400 Loss: 7315.89892578125  > l1:  2631.27392578125  > l2:  4684.625\n",
      "Step:  11500 Loss: 7241.37353515625  > l1:  2797.48779296875  > l2:  4443.8857421875\n",
      "Step:  11600 Loss: 7143.127197265625  > l1:  3176.9130859375  > l2:  3966.214111328125\n",
      "Step:  11700 Loss: 7683.262939453125  > l1:  3234.190185546875  > l2:  4449.07275390625\n",
      "Step:  11800 Loss: 6848.7861328125  > l1:  2692.91748046875  > l2:  4155.86865234375\n",
      "Step:  11900 Loss: 7449.7998046875  > l1:  3368.593505859375  > l2:  4081.206298828125\n",
      "Step:  12000 Loss: 7150.1640625  > l1:  2820.609375  > l2:  4329.5546875\n",
      "Step:  12100 Loss: 6446.707763671875  > l1:  2467.733154296875  > l2:  3978.974609375\n",
      "Step:  12200 Loss: 7143.875732421875  > l1:  3388.429443359375  > l2:  3755.4462890625\n",
      "Step:  12300 Loss: 6202.930419921875  > l1:  2930.46142578125  > l2:  3272.468994140625\n",
      "Step:  12400 Loss: 6147.435546875  > l1:  3112.887451171875  > l2:  3034.548095703125\n",
      "Step:  12500 Loss: 6379.1552734375  > l1:  3100.724365234375  > l2:  3278.430908203125\n",
      "Step:  12600 Loss: 5973.972900390625  > l1:  2832.411865234375  > l2:  3141.56103515625\n",
      "Step:  12700 Loss: 6417.44775390625  > l1:  3136.448974609375  > l2:  3280.998779296875\n",
      "Step:  12800 Loss: 6245.885009765625  > l1:  3025.974609375  > l2:  3219.910400390625\n",
      "Step:  12900 Loss: 5938.699462890625  > l1:  2859.29638671875  > l2:  3079.403076171875\n",
      "Step:  13000 Loss: 6265.361572265625  > l1:  2932.119140625  > l2:  3333.242431640625\n",
      "Step:  13100 Loss: 5952.8671875  > l1:  2937.58447265625  > l2:  3015.28271484375\n",
      "Step:  13200 Loss: 6117.9970703125  > l1:  3046.90771484375  > l2:  3071.08935546875\n",
      "Step:  13300 Loss: 5971.757568359375  > l1:  3034.283203125  > l2:  2937.474365234375\n",
      "Step:  13400 Loss: 6673.96826171875  > l1:  3067.163818359375  > l2:  3606.804443359375\n",
      "Step:  13500 Loss: 6146.404541015625  > l1:  2812.846435546875  > l2:  3333.55810546875\n",
      "Step:  13600 Loss: 6285.828857421875  > l1:  3231.279052734375  > l2:  3054.5498046875\n",
      "Step:  13700 Loss: 5677.092529296875  > l1:  2907.5400390625  > l2:  2769.552490234375\n",
      "Step:  13800 Loss: 5597.005859375  > l1:  3098.938232421875  > l2:  2498.067626953125\n",
      "Step:  13900 Loss: 5905.569091796875  > l1:  3371.79296875  > l2:  2533.776123046875\n",
      "Step:  14000 Loss: 5499.98193359375  > l1:  3153.648193359375  > l2:  2346.333740234375\n",
      "Step:  14100 Loss: 5190.15283203125  > l1:  2778.348876953125  > l2:  2411.803955078125\n",
      "Step:  14200 Loss: 5668.427490234375  > l1:  3309.174560546875  > l2:  2359.2529296875\n",
      "Step:  14300 Loss: 5629.800048828125  > l1:  3488.322021484375  > l2:  2141.47802734375\n",
      "Step:  14400 Loss: 5317.743896484375  > l1:  3211.72119140625  > l2:  2106.022705078125\n",
      "Step:  14500 Loss: 5204.9937744140625  > l1:  3506.626953125  > l2:  1698.3668212890625\n",
      "Step:  14600 Loss: 5018.2401123046875  > l1:  3186.854248046875  > l2:  1831.3858642578125\n",
      "Step:  14700 Loss: 5733.990478515625  > l1:  3691.830810546875  > l2:  2042.15966796875\n",
      "Step:  14800 Loss: 5214.985107421875  > l1:  3075.953125  > l2:  2139.031982421875\n",
      "Step:  14900 Loss: 4772.6123046875  > l1:  3145.9482421875  > l2:  1626.6640625\n",
      "Step:  15000 Loss: 5632.86962890625  > l1:  3190.130859375  > l2:  2442.73876953125\n",
      "Step:  15100 Loss: 5941.26953125  > l1:  4183.68505859375  > l2:  1757.58447265625\n",
      "Step:  15200 Loss: 4931.7816162109375  > l1:  2900.285400390625  > l2:  2031.4962158203125\n",
      "Step:  15300 Loss: 5510.412353515625  > l1:  3363.294189453125  > l2:  2147.1181640625\n",
      "Step:  15400 Loss: 5549.94140625  > l1:  3446.022705078125  > l2:  2103.918701171875\n",
      "Step:  15500 Loss: 5192.498291015625  > l1:  3285.430908203125  > l2:  1907.0673828125\n",
      "Step:  15600 Loss: 5423.67041015625  > l1:  3531.001953125  > l2:  1892.66845703125\n",
      "Step:  15700 Loss: 5261.341552734375  > l1:  2992.149169921875  > l2:  2269.1923828125\n",
      "Step:  15800 Loss: 5417.59326171875  > l1:  3212.514404296875  > l2:  2205.078857421875\n",
      "Step:  15900 Loss: 5020.62451171875  > l1:  3122.8251953125  > l2:  1897.79931640625\n",
      "Step:  16000 Loss: 5165.7677001953125  > l1:  3275.4794921875  > l2:  1890.2882080078125\n",
      "Step:  16100 Loss: 5021.9471435546875  > l1:  3299.220458984375  > l2:  1722.7266845703125\n",
      "Step:  16200 Loss: 5161.65869140625  > l1:  3391.17822265625  > l2:  1770.48046875\n",
      "Step:  16300 Loss: 5699.97216796875  > l1:  3561.921630859375  > l2:  2138.050537109375\n",
      "Step:  16400 Loss: 5063.7261962890625  > l1:  3399.022705078125  > l2:  1664.7034912109375\n",
      "Step:  16500 Loss: 4589.094970703125  > l1:  3003.3759765625  > l2:  1585.718994140625\n",
      "Step:  16600 Loss: 4961.7401123046875  > l1:  2927.659423828125  > l2:  2034.0806884765625\n",
      "Step:  16700 Loss: 5285.33935546875  > l1:  3524.401611328125  > l2:  1760.937744140625\n",
      "Step:  16800 Loss: 4969.37060546875  > l1:  3154.521484375  > l2:  1814.84912109375\n",
      "Step:  16900 Loss: 5663.099365234375  > l1:  3364.864990234375  > l2:  2298.234375\n",
      "Step:  17000 Loss: 4864.80712890625  > l1:  3082.671630859375  > l2:  1782.135498046875\n",
      "Step:  17100 Loss: 4493.5528564453125  > l1:  2794.44775390625  > l2:  1699.1051025390625\n",
      "Step:  17200 Loss: 4433.2569580078125  > l1:  2840.806884765625  > l2:  1592.4500732421875\n",
      "Step:  17300 Loss: 4992.6202392578125  > l1:  3254.69775390625  > l2:  1737.9224853515625\n",
      "Step:  17400 Loss: 4967.050537109375  > l1:  2874.3134765625  > l2:  2092.737060546875\n",
      "Step:  17500 Loss: 5177.0830078125  > l1:  2865.123779296875  > l2:  2311.959228515625\n",
      "Step:  17600 Loss: 5130.3748779296875  > l1:  3564.080078125  > l2:  1566.2947998046875\n",
      "Step:  17700 Loss: 5385.5172119140625  > l1:  3483.727294921875  > l2:  1901.7899169921875\n",
      "Step:  17800 Loss: 4809.764892578125  > l1:  3166.21337890625  > l2:  1643.551513671875\n",
      "Step:  17900 Loss: 5354.275634765625  > l1:  3250.079833984375  > l2:  2104.19580078125\n",
      "Step:  18000 Loss: 4613.933837890625  > l1:  3004.18798828125  > l2:  1609.745849609375\n",
      "Step:  18100 Loss: 5275.8895263671875  > l1:  3335.27197265625  > l2:  1940.6175537109375\n",
      "Step:  18200 Loss: 4980.8167724609375  > l1:  3193.999755859375  > l2:  1786.8170166015625\n",
      "Step:  18300 Loss: 5212.6260986328125  > l1:  3689.472412109375  > l2:  1523.1536865234375\n",
      "Step:  18400 Loss: 4854.349853515625  > l1:  2780.130126953125  > l2:  2074.2197265625\n",
      "Step:  18500 Loss: 5355.3214111328125  > l1:  3437.163818359375  > l2:  1918.1575927734375\n",
      "Step:  18600 Loss: 5079.59814453125  > l1:  3314.667724609375  > l2:  1764.930419921875\n",
      "Step:  18700 Loss: 4912.60888671875  > l1:  3177.550537109375  > l2:  1735.058349609375\n",
      "Step:  18800 Loss: 4944.578857421875  > l1:  2964.8251953125  > l2:  1979.753662109375\n",
      "Step:  18900 Loss: 4175.1126708984375  > l1:  2575.17236328125  > l2:  1599.9403076171875\n",
      "Step:  19000 Loss: 4251.1527099609375  > l1:  2547.110107421875  > l2:  1704.0426025390625\n",
      "Step:  19100 Loss: 4573.1781005859375  > l1:  2743.60009765625  > l2:  1829.5780029296875\n",
      "Step:  19200 Loss: 4270.74755859375  > l1:  2675.05322265625  > l2:  1595.6943359375\n",
      "Step:  19300 Loss: 4820.2745361328125  > l1:  3020.260986328125  > l2:  1800.0135498046875\n",
      "Step:  19400 Loss: 5061.818603515625  > l1:  3314.872802734375  > l2:  1746.94580078125\n",
      "Step:  19500 Loss: 4917.0616455078125  > l1:  3048.73486328125  > l2:  1868.3267822265625\n",
      "Step:  19600 Loss: 4544.3450927734375  > l1:  2810.390380859375  > l2:  1733.9547119140625\n",
      "Step:  19700 Loss: 4200.0042724609375  > l1:  2727.249267578125  > l2:  1472.7550048828125\n",
      "Step:  19800 Loss: 4779.9801025390625  > l1:  2873.58984375  > l2:  1906.3902587890625\n",
      "Step:  19900 Loss: 4459.5540771484375  > l1:  2778.185791015625  > l2:  1681.3682861328125\n",
      "Step:  20000 Loss: 4805.2425537109375  > l1:  2883.226806640625  > l2:  1922.0157470703125\n",
      "Step:  20100 Loss: 4745.700439453125  > l1:  2942.920166015625  > l2:  1802.7802734375\n",
      "Step:  20200 Loss: 5032.881103515625  > l1:  3148.216552734375  > l2:  1884.66455078125\n",
      "Step:  20300 Loss: 4817.8944091796875  > l1:  3282.243896484375  > l2:  1535.6505126953125\n",
      "Step:  20400 Loss: 4617.4320068359375  > l1:  3182.25732421875  > l2:  1435.1746826171875\n",
      "Step:  20500 Loss: 3778.047119140625  > l1:  2327.065185546875  > l2:  1450.98193359375\n",
      "Step:  20600 Loss: 4129.22705078125  > l1:  2840.63720703125  > l2:  1288.58984375\n",
      "Step:  20700 Loss: 4592.118408203125  > l1:  2916.427001953125  > l2:  1675.69140625\n",
      "Step:  20800 Loss: 4426.1982421875  > l1:  2874.808349609375  > l2:  1551.389892578125\n",
      "Step:  20900 Loss: 4764.729248046875  > l1:  2847.90771484375  > l2:  1916.821533203125\n",
      "Step:  21000 Loss: 4291.212646484375  > l1:  2943.811279296875  > l2:  1347.4013671875\n",
      "Step:  21100 Loss: 4389.374267578125  > l1:  2610.34033203125  > l2:  1779.033935546875\n",
      "Step:  21200 Loss: 4748.03125  > l1:  2774.19384765625  > l2:  1973.83740234375\n",
      "Step:  21300 Loss: 4090.91015625  > l1:  2770.36279296875  > l2:  1320.54736328125\n",
      "Step:  21400 Loss: 4681.895751953125  > l1:  2922.09423828125  > l2:  1759.801513671875\n",
      "Step:  21500 Loss: 4026.5440673828125  > l1:  2630.949951171875  > l2:  1395.5941162109375\n",
      "Step:  21600 Loss: 4053.469970703125  > l1:  2521.127197265625  > l2:  1532.3427734375\n",
      "Step:  21700 Loss: 4704.17236328125  > l1:  2689.499755859375  > l2:  2014.672607421875\n",
      "Step:  21800 Loss: 4336.272705078125  > l1:  2973.085693359375  > l2:  1363.18701171875\n",
      "Step:  21900 Loss: 4382.8082275390625  > l1:  2475.8955078125  > l2:  1906.9127197265625\n",
      "Step:  22000 Loss: 4108.37158203125  > l1:  2966.025634765625  > l2:  1142.345947265625\n",
      "Step:  22100 Loss: 4740.439453125  > l1:  2780.313232421875  > l2:  1960.126220703125\n",
      "Step:  22200 Loss: 4521.3201904296875  > l1:  2682.382568359375  > l2:  1838.9376220703125\n",
      "Step:  22300 Loss: 4844.4051513671875  > l1:  3416.66796875  > l2:  1427.7371826171875\n",
      "Step:  22400 Loss: 4294.1900634765625  > l1:  2655.0546875  > l2:  1639.1353759765625\n",
      "Step:  22500 Loss: 4465.4149169921875  > l1:  2644.291259765625  > l2:  1821.1236572265625\n",
      "Step:  22600 Loss: 4595.0262451171875  > l1:  3023.221435546875  > l2:  1571.8048095703125\n",
      "Step:  22700 Loss: 3935.0228271484375  > l1:  2718.670654296875  > l2:  1216.3521728515625\n",
      "Step:  22800 Loss: 4934.0587158203125  > l1:  3019.02734375  > l2:  1915.0313720703125\n",
      "Step:  22900 Loss: 4296.2288818359375  > l1:  2572.481201171875  > l2:  1723.7476806640625\n",
      "Step:  23000 Loss: 4405.361572265625  > l1:  2864.128662109375  > l2:  1541.23291015625\n",
      "Step:  23100 Loss: 3831.4542236328125  > l1:  2354.7158203125  > l2:  1476.7384033203125\n",
      "Step:  23200 Loss: 4091.0986328125  > l1:  2675.11865234375  > l2:  1415.97998046875\n",
      "Step:  23300 Loss: 4794.484130859375  > l1:  2510.626708984375  > l2:  2283.857421875\n",
      "Step:  23400 Loss: 5037.59423828125  > l1:  2771.09130859375  > l2:  2266.5029296875\n",
      "Step:  23500 Loss: 4198.751953125  > l1:  2711.2041015625  > l2:  1487.5478515625\n",
      "Step:  23600 Loss: 4654.0482177734375  > l1:  2911.516357421875  > l2:  1742.5318603515625\n",
      "Step:  23700 Loss: 4787.2802734375  > l1:  3200.1015625  > l2:  1587.1787109375\n",
      "Step:  23800 Loss: 4034.6556396484375  > l1:  2842.014404296875  > l2:  1192.6412353515625\n",
      "Step:  23900 Loss: 4202.298828125  > l1:  2712.1162109375  > l2:  1490.1826171875\n",
      "Step:  24000 Loss: 4246.6162109375  > l1:  2323.168212890625  > l2:  1923.447998046875\n",
      "Step:  24100 Loss: 3942.7974853515625  > l1:  2346.5498046875  > l2:  1596.2476806640625\n",
      "Step:  24200 Loss: 4151.2052001953125  > l1:  2727.107421875  > l2:  1424.0977783203125\n",
      "Step:  24300 Loss: 4347.337890625  > l1:  2941.693115234375  > l2:  1405.644775390625\n",
      "Step:  24400 Loss: 4932.9935302734375  > l1:  3230.389892578125  > l2:  1702.6036376953125\n",
      "Step:  24500 Loss: 3980.080322265625  > l1:  2698.056640625  > l2:  1282.023681640625\n",
      "Step:  24600 Loss: 4513.78173828125  > l1:  2721.002197265625  > l2:  1792.779541015625\n",
      "Step:  24700 Loss: 3987.3546142578125  > l1:  2465.459716796875  > l2:  1521.8948974609375\n",
      "Step:  24800 Loss: 4174.10205078125  > l1:  2756.6982421875  > l2:  1417.40380859375\n",
      "Step:  24900 Loss: 4369.991943359375  > l1:  3066.478271484375  > l2:  1303.513671875\n",
      "Step:  25000 Loss: 4221.0228271484375  > l1:  2659.25927734375  > l2:  1561.7635498046875\n",
      "Step:  25100 Loss: 4192.575927734375  > l1:  2719.234619140625  > l2:  1473.34130859375\n",
      "Step:  25200 Loss: 4617.7408447265625  > l1:  2744.8583984375  > l2:  1872.8824462890625\n",
      "Step:  25300 Loss: 4709.015625  > l1:  2775.171875  > l2:  1933.84375\n",
      "Step:  25400 Loss: 4124.7396240234375  > l1:  2793.994873046875  > l2:  1330.7447509765625\n",
      "Step:  25500 Loss: 4663.5787353515625  > l1:  2809.806640625  > l2:  1853.7720947265625\n",
      "Step:  25600 Loss: 4259.2640380859375  > l1:  2575.31884765625  > l2:  1683.9451904296875\n",
      "Step:  25700 Loss: 4829.159423828125  > l1:  3155.093017578125  > l2:  1674.06640625\n",
      "Step:  25800 Loss: 4458.556396484375  > l1:  2905.40771484375  > l2:  1553.148681640625\n",
      "Step:  25900 Loss: 4008.8572998046875  > l1:  2633.157470703125  > l2:  1375.6998291015625\n",
      "Step:  26000 Loss: 4200.021728515625  > l1:  2633.42333984375  > l2:  1566.598388671875\n",
      "Step:  26100 Loss: 3672.2841796875  > l1:  2433.587890625  > l2:  1238.6962890625\n",
      "Step:  26200 Loss: 4165.244873046875  > l1:  2719.68408203125  > l2:  1445.560791015625\n",
      "Step:  26300 Loss: 3890.638671875  > l1:  2688.512939453125  > l2:  1202.125732421875\n",
      "Step:  26400 Loss: 3955.3782958984375  > l1:  2783.40869140625  > l2:  1171.9696044921875\n",
      "Step:  26500 Loss: 3814.3587646484375  > l1:  2488.659912109375  > l2:  1325.6988525390625\n",
      "Step:  26600 Loss: 4218.7623291015625  > l1:  2607.30859375  > l2:  1611.4537353515625\n",
      "Step:  26700 Loss: 3792.6483154296875  > l1:  2472.4638671875  > l2:  1320.1844482421875\n",
      "Step:  26800 Loss: 4024.1505126953125  > l1:  3000.393798828125  > l2:  1023.7567138671875\n",
      "Step:  26900 Loss: 4249.8087158203125  > l1:  2634.843505859375  > l2:  1614.9652099609375\n",
      "Step:  27000 Loss: 4349.119384765625  > l1:  2959.072998046875  > l2:  1390.04638671875\n",
      "Step:  27100 Loss: 4703.4111328125  > l1:  3073.967041015625  > l2:  1629.444091796875\n",
      "Step:  27200 Loss: 3885.77001953125  > l1:  2333.462646484375  > l2:  1552.307373046875\n",
      "Step:  27300 Loss: 4361.3424072265625  > l1:  2779.8896484375  > l2:  1581.4527587890625\n",
      "Step:  27400 Loss: 4274.6116943359375  > l1:  2917.13720703125  > l2:  1357.4744873046875\n",
      "Step:  27500 Loss: 3993.8582763671875  > l1:  2683.272216796875  > l2:  1310.5860595703125\n",
      "Step:  27600 Loss: 3799.8504638671875  > l1:  2427.844482421875  > l2:  1372.0059814453125\n",
      "Step:  27700 Loss: 3883.0009765625  > l1:  2656.864013671875  > l2:  1226.136962890625\n",
      "Step:  27800 Loss: 4057.6282958984375  > l1:  2715.056640625  > l2:  1342.5716552734375\n",
      "Step:  27900 Loss: 3825.7774658203125  > l1:  2413.81884765625  > l2:  1411.9586181640625\n",
      "Step:  28000 Loss: 4393.5399169921875  > l1:  3041.070556640625  > l2:  1352.4693603515625\n",
      "Step:  28100 Loss: 4058.188232421875  > l1:  2548.68359375  > l2:  1509.504638671875\n",
      "Step:  28200 Loss: 3718.2149658203125  > l1:  2325.51708984375  > l2:  1392.6978759765625\n",
      "Step:  28300 Loss: 3994.9622802734375  > l1:  2547.786865234375  > l2:  1447.1754150390625\n",
      "Step:  28400 Loss: 3828.6390380859375  > l1:  2429.89453125  > l2:  1398.7445068359375\n",
      "Step:  28500 Loss: 4032.391357421875  > l1:  2712.382080078125  > l2:  1320.00927734375\n",
      "Step:  28600 Loss: 4350.0009765625  > l1:  2984.403076171875  > l2:  1365.597900390625\n",
      "Step:  28700 Loss: 3499.3946533203125  > l1:  2354.153564453125  > l2:  1145.2410888671875\n",
      "Step:  28800 Loss: 3993.1375732421875  > l1:  2702.222412109375  > l2:  1290.9151611328125\n",
      "Step:  28900 Loss: 4766.435546875  > l1:  3285.859375  > l2:  1480.576171875\n",
      "Step:  29000 Loss: 4074.50048828125  > l1:  2749.8037109375  > l2:  1324.69677734375\n",
      "Step:  29100 Loss: 4523.0172119140625  > l1:  2491.719970703125  > l2:  2031.2972412109375\n",
      "Step:  29200 Loss: 4553.2061767578125  > l1:  3030.684814453125  > l2:  1522.5213623046875\n",
      "Step:  29300 Loss: 4980.3994140625  > l1:  2899.21728515625  > l2:  2081.18212890625\n",
      "Step:  29400 Loss: 4309.560302734375  > l1:  3078.836181640625  > l2:  1230.72412109375\n",
      "Step:  29500 Loss: 4375.317626953125  > l1:  2816.33935546875  > l2:  1558.978271484375\n",
      "Step:  29600 Loss: 4415.6300048828125  > l1:  2974.979736328125  > l2:  1440.6502685546875\n",
      "Step:  29700 Loss: 3976.1129150390625  > l1:  2631.0263671875  > l2:  1345.0865478515625\n",
      "Step:  29800 Loss: 4040.6673583984375  > l1:  2672.831787109375  > l2:  1367.8355712890625\n",
      "Step:  29900 Loss: 4020.094970703125  > l1:  2665.948486328125  > l2:  1354.146484375\n"
     ]
    }
   ],
   "source": [
    "if run_training_loop:\n",
    "    print(\"Start Training\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "    STARTCUDATIME = torch.cuda.Event(enable_timing=True)\n",
    "    ENDCUDATIME = torch.cuda.Event(enable_timing=True)\n",
    "    losses = []\n",
    "    timings = []\n",
    "    clock = []\n",
    "    \n",
    "    name_and_training_dir = trainer.name_and_training_dir\n",
    "    Handles_post = trainer.Handles_post\n",
    "    training_settings = trainer.training_settings\n",
    "    \n",
    "    for e in range(1, trainer.TOTAL_TRAINING_STEPS):\n",
    "        num_handles = Handles_post.num_handles\n",
    "        batch_size = int(training_settings[\"TBatchSize\"])\n",
    "        batchTs = getBatchOfTs(num_handles, batch_size, e).to(device).float()\n",
    "        t_batchTs = batchTs*float(training_settings[\"TSamplingStdev\"])\n",
    "        STARTCLOCKTIME = time.time()\n",
    "        STARTCUDATIME.record()\n",
    "        l1, l2 = trainer.train_step(\n",
    "            Handles_post,\n",
    "            trainer.t_O,\n",
    "            trainer.t_YMs,\n",
    "            trainer.t_PRs,\n",
    "            trainer.loss_fcn,\n",
    "            t_batchTs,\n",
    "            e\n",
    "        )\n",
    "        ENDCUDATIME.record()\n",
    "    \n",
    "        # Waits for everything to finish running\n",
    "        torch.cuda.synchronize()\n",
    "        ENDCLOCKTIME = time.time()\n",
    "    \n",
    "        timings.append(STARTCUDATIME.elapsed_time(ENDCUDATIME))  # milliseconds\n",
    "        clock.append(ENDCLOCKTIME - STARTCLOCKTIME)\n",
    "    \n",
    "        if e % 100 == 0:\n",
    "            print(\"Step: \", e, \"Loss:\", l1+l2,\" > l1: \", l1, \" > l2: \", l2)\n",
    "        losses.append(np.array([l1+l2, l1, l2]))\n",
    "    \n",
    "        if e % int(training_settings[\"SaveHandleIts\"]) == 0:\n",
    "        # Compute the moving average\n",
    "    \n",
    "            # save loss and handle state at current its\n",
    "            torch.save(clock, name_and_training_dir+\"/clocktimes-its-\"+str(e))\n",
    "            torch.save(timings, name_and_training_dir+\"/timings-its-\"+str(e))\n",
    "            torch.save(losses, name_and_training_dir+\"/losses-its-\"+str(e))\n",
    "            torch.save(Handles_post, name_and_training_dir+\"/Handles_post-its-\"+str(e))\n",
    "    \n",
    "    \n",
    "            torch.save(clock, name_and_training_dir+\"/clocktimes\")\n",
    "            torch.save(timings, name_and_training_dir+\"/timings\")\n",
    "            torch.save(losses, name_and_training_dir+\"/losses\")\n",
    "            torch.save(Handles_post, name_and_training_dir+\"/Handles_post\")\n",
    "    \n",
    "        if e % int(training_settings[\"SaveSampleIts\"]) == 0:\n",
    "            O = torch.tensor(trainer.np_object[\"ObjectSamplePts\"], dtype=torch.float32, device=device)\n",
    "            for b in range(batchTs.shape[0]):\n",
    "                Ts = batchTs[b,:,:,:]\n",
    "                O_new = trainer.getX(Ts, O, Handles_post)\n",
    "                write_ply(name_and_training_dir+\"/training-epoch-\"+str(e)+\"-batch-\"+str(b)+\".ply\", O_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e03c34c4-2f9d-4716-a52f-66299d69e4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_training_loop:\n",
    "    torch.save(clock, name_and_training_dir+\"/clocktimes\")\n",
    "    torch.save(timings, name_and_training_dir+\"/timings\")\n",
    "    torch.save(losses, name_and_training_dir+\"/losses\")\n",
    "    torch.save(Handles_post, name_and_training_dir+\"/Handles_post\")\n",
    "    torch.save(trainer.Handles_pre, name_and_training_dir+\"/Handles_pre\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516dc123-0a6f-4d4a-8ae9-f39e9564c7f0",
   "metadata": {},
   "source": [
    "## 4. Analyze Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c3524c-fde8-4ee3-ab17-9f043dd8ebd3",
   "metadata": {},
   "source": [
    "This step lets us view the training progress in terms of loss curves, and what the optimized skinning weights look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d0f5808-2a10-4e88-9555-6d52ae19a161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from SimplicitHelpers import *\n",
    "import json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e5843735-1933-41b2-bd53-bfa4afd9f2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.52681676e+07 1.99960046e+03 6.52661680e+07]\n",
      " [3.54301815e+07 1.26949512e+03 3.54289120e+07]\n",
      " [1.91335600e+07 5.16043701e+02 1.91330440e+07]\n",
      " ...\n",
      " [3.98371912e+03 2.49603491e+03 1.48768420e+03]\n",
      " [4.03378857e+03 2.82410645e+03 1.20968213e+03]\n",
      " [4.51615747e+03 2.74493604e+03 1.77122144e+03]]\n",
      "linear_relu_stack.0.weight torch.Size([64, 3])\n",
      "linear_relu_stack.0.bias torch.Size([64])\n",
      "linear_relu_stack.2.weight torch.Size([64, 64])\n",
      "linear_relu_stack.2.bias torch.Size([64])\n",
      "linear_relu_stack.4.weight torch.Size([64, 64])\n",
      "linear_relu_stack.4.bias torch.Size([64])\n",
      "linear_relu_stack.6.weight torch.Size([64, 64])\n",
      "linear_relu_stack.6.bias torch.Size([64])\n",
      "linear_relu_stack.8.weight torch.Size([64, 64])\n",
      "linear_relu_stack.8.bias torch.Size([64])\n",
      "linear_relu_stack.10.weight torch.Size([64, 64])\n",
      "linear_relu_stack.10.bias torch.Size([64])\n",
      "linear_relu_stack.12.weight torch.Size([64, 64])\n",
      "linear_relu_stack.12.bias torch.Size([64])\n",
      "linear_relu_stack.14.weight torch.Size([64, 64])\n",
      "linear_relu_stack.14.bias torch.Size([64])\n",
      "linear_relu_stack.16.weight torch.Size([64, 64])\n",
      "linear_relu_stack.16.bias torch.Size([64])\n",
      "linear_relu_stack.18.weight torch.Size([64, 64])\n",
      "linear_relu_stack.18.bias torch.Size([64])\n",
      "linear_relu_stack.20.weight torch.Size([64, 64])\n",
      "linear_relu_stack.20.bias torch.Size([64])\n",
      "linear_relu_stack.22.weight torch.Size([40, 64])\n",
      "linear_relu_stack.22.bias torch.Size([40])\n"
     ]
    }
   ],
   "source": [
    "if run_analysis:\n",
    "    if os.path.exists(object_name+\"/\"+training_name+\"-training/timings\"):\n",
    "        timings = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/timings\")\n",
    "    else:\n",
    "        timings = None\n",
    "    \n",
    "    losses = np.array(torch.load(object_name+\"/\"+training_name+\"-training\" + \"/losses\"))\n",
    "    print(losses)\n",
    "    try:\n",
    "        losses = losses[:,0]\n",
    "    except IndexError:\n",
    "        losses = np.expand_dims(losses, axis=-1)\n",
    "        losses = losses[:,0]\n",
    "    \n",
    "    Handles_post = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_post\")\n",
    "    Handles_pre = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_pre\")\n",
    "    \n",
    "    for nnnn, pppp in Handles_post.model.named_parameters():\n",
    "        print(nnnn, pppp.size())\n",
    "    \n",
    "    # Get a list of all files in the folder\n",
    "    all_files = os.listdir(object_name+\"/\"+training_name+\"-training\" + \"/\")\n",
    "    # Filter files with the \"training\" prefix\n",
    "    training_files = [filename for filename in all_files if filename.startswith('Handles_post-its-')]\n",
    "    epoch_list = sorted(list(set([int(f.split(\"Handles_post-its-\")[1].split(\"-\")[0]) for f in training_files])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "82bbf6ef-c4a7-45b5-a404-6515ce287580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.1296,  0.0525, -0.2072,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0525,  2.2978, -0.0910,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2072, -0.0910,  1.4641,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  3.1906, -0.0517,  1.4456],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ..., -0.0517,  1.5904,  1.4289],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  1.4456,  1.4289,  8.8206]])\n",
      "ALSO WTW\n",
      "[[ 8.593992   -0.08048961 -0.17850257 ... -0.09306474 -0.07410429\n",
      "   0.25267   ]\n",
      " [-0.08048961  8.681902   -0.27634528 ...  0.29026595 -0.08047968\n",
      "  -0.10190795]\n",
      " [-0.17850257 -0.27634528  8.966825   ... -0.1719874   0.272114\n",
      "  -0.26967916]\n",
      " ...\n",
      " [-0.09306474  0.29026595 -0.1719874  ...  8.796559   -0.05691256\n",
      "  -0.2772351 ]\n",
      " [-0.07410429 -0.08047968  0.272114   ... -0.05691256  9.144781\n",
      "  -0.17680295]\n",
      " [ 0.25267    -0.10190795 -0.26967916 ... -0.2772351  -0.17680295\n",
      "   8.820625  ]]\n"
     ]
    }
   ],
   "source": [
    "if run_analysis:\n",
    "    Handles_post.to_device(device)\n",
    "    Handles_pre.to_device(device)\n",
    "    Handles_pre.eval()\n",
    "    t_O = torch.tensor(np_object[\"ObjectSamplePts\"]).to(device)\n",
    "    \n",
    "    # Compute the moving average\n",
    "    window_size = 100\n",
    "    ma = moving_average(losses[500:], window_size)\n",
    "    \n",
    "    # Plot the loss curve\n",
    "    plt.plot(ma)\n",
    "    plt.title('Loss curve')\n",
    "    plt.xlabel('Iterations')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show()\n",
    "    \n",
    "    if timings is not None:\n",
    "        # Compute the moving average\n",
    "        window_size = 100\n",
    "        ma = moving_average(timings[500:], window_size)\n",
    "    \n",
    "        # Plot the loss curve\n",
    "        plt.plot(ma)\n",
    "        plt.title('Timings')\n",
    "        plt.xlabel('Iterations')\n",
    "        plt.ylabel('Times in ms')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    np_W0, np_X0, np_G0 = test(Handles_pre, t_O, int(t_O.shape[0]))\n",
    "    np_W, np_X, np_G = test(Handles_post, t_O, int(t_O.shape[0]))\n",
    "    \n",
    "    X0 = torch.tensor(np_X)\n",
    "    W  = torch.tensor(np_W)\n",
    "    \n",
    "    num_handles = W.shape[1]\n",
    "    num_samples = X0.shape[0]\n",
    "    X03 = torch.cat((X0, torch.ones(X0.shape[0]).unsqueeze(-1)), dim=1)\n",
    "    X03reps = X03.repeat_interleave(3, dim=0).repeat((1, 3*num_handles))\n",
    "    Wreps = W.repeat_interleave(12, dim=1).repeat_interleave(3, dim=0)\n",
    "    WX03reps = torch.mul(Wreps, X03reps)\n",
    "    Bsetup = torch.kron(torch.ones(num_samples).unsqueeze(-1), torch.eye(3)).repeat((1,num_handles))\n",
    "    Bmask = torch.repeat_interleave(Bsetup, 4, dim=1)\n",
    "    \n",
    "    B = torch.mul(Bmask, WX03reps)\n",
    "    print(B.T @ B)\n",
    "    print(\"ALSO WTW\")\n",
    "    print(np_W.T@np_W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1db34587-bfd1-42f8-8a5f-2547c69cd444",
   "metadata": {},
   "outputs": [],
   "source": [
    "if run_analysis:\n",
    "    global points \n",
    "    global weights\n",
    "    points = np_X \n",
    "    weights = np_W \n",
    "    \n",
    "    global handle_num\n",
    "    global epoch_num\n",
    "    handle_num = 0\n",
    "    epoch_num = len(epoch_list)\n",
    "    \n",
    "    max_all_w = np.max(np.max(weights))\n",
    "    min_all_w = np.min(np.min(weights))\n",
    "    \n",
    "    # Combo box to choose from options\n",
    "    # There, the options are a list of strings in `ui_options`,\n",
    "    # and the currently selected element is stored in `ui_options_selected`.\n",
    "    def callback():\n",
    "        global handle_num, points, weights, epoch_num, epoch_list\n",
    "        changed2, epoch_num = psim.SliderInt(\"Epoch:\", epoch_num, v_min=0, v_max=len(epoch_list))\n",
    "        changed1, handle_num = psim.SliderInt(\"Handles:\", handle_num, v_min=0, v_max=weights.shape[1]-1)\n",
    "        if changed1 or changed2:\n",
    "            ii = int(handle_num)\n",
    "            if epoch_num == len(epoch_list):        \n",
    "                weights, points, np_G = test(Handles_post, t_O, int(t_O.shape[0]))\n",
    "            else:\n",
    "                ei = epoch_list[epoch_num]\n",
    "                Handles_its = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_post-its-\"+str(ei))\n",
    "                Handles_its.to_device(device)\n",
    "                weights, points,  np_G = test(Handles_its, t_O, int(t_O.shape[0]))\n",
    "    \n",
    "            w = weights[:, ii]\n",
    "            # ps_cloud.add_scalar_quantity(\"Weight: \"+str(ii), w, enabled=True)\n",
    "            # Normalize the weights to the range [0, 1]\n",
    "            # w_norm = (w - min_all_w) / (max_all_w - min_all_w)\n",
    "            ps_cloud.update_point_positions(points)\n",
    "            ps_cloud.add_scalar_quantity(\"Weight: \"+str(ii), w, enabled=True, datatype=\"symmetric\")\n",
    "            # color_mat = np.column_stack((w_norm, w_norm, w_norm))\n",
    "            # color_mat[:,1:2] = 1\n",
    "            # # print(color_mat)\n",
    "            # ps_cloud.add_color_quantity(\"weights: \"+str(ii), color_mat, enabled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57202adf-9b67-4e0d-b1f4-e3faa5ad38ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the plot\n",
    "if show_plot:\n",
    "    ps.init()\n",
    "    ps.remove_all_structures()\n",
    "    ps_cloud = ps.register_point_cloud(\"samples\", points, enabled=True)\n",
    "    ps_cloud.add_scalar_quantity(\"Weight: \"+str(0), weights[:,0], enabled=True, datatype=\"symmetric\")\n",
    "    ps_unit_cloud = ps.register_point_cloud(\"UnitSphere\",  np.array([[0,0,0],[1,0,0]]), enabled=True, radius=1)\n",
    "    ps.set_user_callback(callback)\n",
    "    ps.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fac54dd-2015-4a75-8f8c-9ae7e5208c39",
   "metadata": {},
   "source": [
    "## 5. Phyisical Simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fc335-31bd-4c0d-8c61-3c9c38875ce0",
   "metadata": {},
   "source": [
    "From the file `PhysicsSimMultiObject_5.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fd1b77b7-9ce0-42ef-895c-628f9e874be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F \n",
    "import random, os, sys, json\n",
    "from SimplicitHelpers import *\n",
    "from PhysicsHelpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29cd46b7-e95f-435f-a109-18e1005305b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def E_Coll_Penalty(X, col_indices):\n",
    "    col_penalty = torch.tensor(0, dtype=torch.float32, device=device)\n",
    "\n",
    "    for i in range(torch.max(col_indices)):\n",
    "        j = i+1\n",
    "        inds_where_object_i = torch.nonzero(col_indices == i).squeeze()\n",
    "        inds_where_object_j = torch.nonzero(col_indices == j).squeeze()\n",
    "\n",
    "        M = X[inds_where_object_i, :]\n",
    "        V = X[inds_where_object_j, :]\n",
    "\n",
    "        col_penalty += torch.sum(-1*torch.log(torch.cdist(M, V, p=2)**2))\n",
    "    return col_penalty\n",
    "\n",
    "def E_pot(X0,  W, Faces, YMs, Ts, Handles):\n",
    "    poisson = float(0.45)\n",
    "    mus = YMs/(2*(1+poisson)) #shead modulus\n",
    "    lams = YMs*poisson/((1+poisson)*(1-2*poisson)) #\n",
    "\n",
    "    def elastic_energy(F, mu, lam):\n",
    "        E = neohookean_E2(mu, lam, F[0,:,:])\n",
    "        return E\n",
    "    \n",
    "    def x(x0):\n",
    "        x0_i = x0.unsqueeze(0)\n",
    "        x03 = torch.cat((x0_i, torch.tensor([[1]], device=device)), dim=1)\n",
    "        t_W = torch.cat((Handles.getAllWeightsSoftmax(x0_i), torch.tensor([[1]]).to(device)), dim=1).T\n",
    "        \n",
    "        def inner_over_handles(T, w):\n",
    "            return w*T@x03.T\n",
    "\n",
    "        wTx03s = torch.vmap(inner_over_handles)(Ts, t_W)\n",
    "        x_i =  torch.sum(wTx03s, dim=0)\n",
    "        return x_i.T +x0_i\n",
    "    \n",
    "    pt_wise_Fs = torch.vmap(torch.func.jacrev(x), randomness=\"same\")(X0)\n",
    "    pt_wise_E = torch.vmap(elastic_energy, randomness=\"same\")(pt_wise_Fs, mus, lams)\n",
    "    totE = (np_object[\"ObjectVol\"]/X0.shape[0])*pt_wise_E.sum()\n",
    "    return totE\n",
    "\n",
    "def penalty(X0, x0_flat, B, J, z):\n",
    "\n",
    "    global simulation_iteration, move_mask, dt, barrier_T\n",
    "    x_flat = B@z + x0_flat\n",
    "\n",
    "    #### Fixed vertices\n",
    "    totE = float(scene[\"penalty_spring_fixed_weight\"])*z.T@B.T@J@J.T@B@z\n",
    "\n",
    "    # collE = float(scene[\"penalty_log_barrier_collisions\"])*E_Coll_Penalty(x_flat.reshape(-1,3), col_indices=ColMap)\n",
    "\n",
    "    ##### Moving vertices\n",
    "    movE = torch.tensor([[0]], dtype=torch.float32).to(device)\n",
    "    if float(scene[\"penalty_spring_moving_weight\"])>0:\n",
    "        moving_verts = x0_flat[move_mask].reshape(-1,3).detach()\n",
    "        l_dict = {\"moving_verts\": moving_verts, \"dt\":dt, \"simulation_iteration\": simulation_iteration}\n",
    "        exec(scene[\"SimplicitObjects\"][0][\"MoveBC_code\"], globals(), l_dict)\n",
    "        updated_vert_positions = l_dict[\"updated_vert_positions\"]\n",
    "        if updated_vert_positions != None:\n",
    "            Xs = x_flat[move_mask].reshape(-1, 3)\n",
    "            movE = float(scene[\"penalty_spring_moving_weight\"])*torch.sum(torch.square(updated_vert_positions - Xs))\n",
    "\n",
    "    \n",
    "    #pokes\n",
    "    pokyE = torch.tensor([[0]], dtype=torch.float32).to(device)\n",
    "    if len(scene[\"CollisionObjects\"])>0:\n",
    "        dist_to_poky = torch.tensor([0], dtype=torch.float32).to(device)\n",
    "        for p in range(len(scene[\"CollisionObjects\"])):           \n",
    "            collision_object = torch.tensor(scene[\"CollisionObjects\"][p][\"Position\"], dtype=torch.float32, device=device)\n",
    "            l_dict = {\"collision_obj\": collision_object, \"dt\":dt, \"simulation_iteration\": simulation_iteration}\n",
    "            exec(scene[\"CollisionObjects\"][p][\"Update_code\"], globals(), l_dict)\n",
    "            collision_object = l_dict[\"pos\"]\n",
    "            dist_to_poky = torch.sqrt(torch.sum((x_flat.reshape(-1,3) - collision_object)**2, dim=1))\n",
    "            min_dist_to_poky = torch.min(dist_to_poky)\n",
    "            collision_object_rad = float(scene[\"CollisionObjects\"][0][\"Radius\"])\n",
    "            if torch.min(dist_to_poky)<collision_object_rad:\n",
    "                pokyE += torch.tensor(float(\"inf\"), dtype=torch.float32).to(device)\n",
    "            else:\n",
    "                log_dist_to_poky =-(float(scene[\"BarrierInitStiffness\"])/(float(scene[\"BarrierDec\"])**barrier_T))*torch.log(min_dist_to_poky - collision_object_rad) #log barrier is inf at collision_object_rad\n",
    "                if log_dist_to_poky>0:\n",
    "                    pokyE += log_dist_to_poky\n",
    "                # pos_indx = log_dist_to_poky>0\n",
    "                # pokyE += 1*torch.sum(log_dist_to_poky[pos_indx])\n",
    "\n",
    "\n",
    "    #### Floor\n",
    "    floorE = torch.tensor([[0]], dtype=torch.float32).to(device)\n",
    "    if float(scene[\"penalty_spring_floor_weight\"])>0:\n",
    "        ys = x_flat[1::3]\n",
    "        masked_values = ys[ys<float(scene[\"Floor\"])] - float(scene[\"Floor\"])\n",
    "        floorE = float(scene[\"penalty_spring_floor_weight\"])*torch.sum(masked_values**2)\n",
    "\n",
    "    if len(scene[\"CollisionObjects\"])>0:\n",
    "        print(\"         PokeE: \", pokyE, barrier_T, torch.min(dist_to_poky))\n",
    "    return totE + floorE + movE + pokyE# + collE\n",
    "\n",
    "def potential_energy(Phi, W, z, newx, Mg, X0, Faces, YMs,  x0_flat, J, B, Handles):  \n",
    "    pe = penalty(X0, x0_flat, B, J, z)\n",
    "    T = z.reshape(-1, 3,4)\n",
    "    le = Phi(X0, W, Faces, YMs, T, Handles) #E_pot(X0, T, Handles)\n",
    "    ge = newx.T @ Mg\n",
    "    return le + ge + pe\n",
    "\n",
    "def line_search(func, x, direction, gradient, alpha=0.5, beta=0.5):\n",
    "    t = 10.0  # Initial step size\n",
    "    for _ in range(int(scene[\"LSIts\"])):\n",
    "        x_new = x + t * direction\n",
    "        f_new = func(x_new)\n",
    "        f = func(x)\n",
    "        gTd = gradient.T@direction\n",
    "        if f_new <= f + alpha * t * gTd:\n",
    "            return t\n",
    "        t *= beta  # Reduce the step size\n",
    "\n",
    "    return t  # Return the final step size if max_iters is reached\n",
    "\n",
    "def getBColiNorm(W, X0, i):\n",
    "    # B matrix is the modes\n",
    "    # 3*|verts| x num dofs (|z|)\n",
    "    \n",
    "    t_ind = int(i/12) #row i gets weights from handle t_ind\n",
    "\n",
    "    def nzBColi(wt_n, x_n):\n",
    "        if i%4 ==0:\n",
    "            return wt_n*x_n[0]\n",
    "        elif i%4 ==1:\n",
    "            return wt_n*x_n[1]\n",
    "        elif i%4 ==2:\n",
    "            return wt_n*x_n[2]\n",
    "        elif i%4 ==3:\n",
    "            return wt_n\n",
    "    \n",
    "    nonzero_col_entries = torch.vmap(nzBColi, randomness=\"same\")(W[:, t_ind], X0)\n",
    "\n",
    "    return torch.sum(nonzero_col_entries.square())\n",
    "\n",
    "def simulate(np_X, Faces, np_YMs, np_PRs, np_Rho, WW, Phi, Handles):\n",
    "    global simulation_iteration, move_mask, dt, barrier_T\n",
    "    \n",
    "    states = []\n",
    "    \n",
    "    #nx2 sample points\n",
    "    X0 = torch.tensor(np_X, dtype=torch.float32, requires_grad = True, device=device)\n",
    "    ones_column = torch.ones(X0.shape[0], 1).to(device)\n",
    "    W = torch.cat((Handles.getAllWeightsSoftmax(X0), ones_column), dim=1)\n",
    "\n",
    "    tYMs = torch.tensor(np_YMs, dtype=torch.float32).to(device)\n",
    "    tPRs = torch.tensor(np_PRs, dtype=torch.float32).to(device)\n",
    "    tFaces = torch.tensor(Faces).to(device)\n",
    "\n",
    "    # Use torch.nn.functional.one_hot to create the one-hot matrix for object-wise rigid deformations\n",
    "    # one_hot_matrix = torch.nn.functional.one_hot(tColMap, num_classes=torch.max(tColMap)+1)\n",
    "    # W = torch.cat((W, one_hot_matrix), dim=1)\n",
    "    \n",
    "    # number of handles + 1 for hard coded rigid translations\n",
    "    num_handles = W.shape[1]\n",
    "    num_samples = np_X.shape[0]\n",
    "    \n",
    "\n",
    "    #### Set moving boundary conditions\n",
    "    move_mask = torch.zeros(num_samples*3, dtype=torch.bool)\n",
    "    l_dict = {\"X0\": X0}\n",
    "    exec(scene[\"SimplicitObjects\"][0][\"SetMovingBC_code\"], globals(), l_dict)\n",
    "    indices = l_dict[\"indices\"]\n",
    "    indices = (3*indices).repeat_interleave(3)\n",
    "    indices[1::3] += 1\n",
    "    indices[2::3] += 2; \n",
    "    move_mask[indices] = True \n",
    "\n",
    "    #### Set fixed boundary conditions\n",
    "    # Create a mask to identify rows to be REMOVED\n",
    "    mask = torch.zeros(num_samples*3, dtype=torch.bool)\n",
    "    # execute code in json file to set object's fixed bc\n",
    "    l_dict = {\"X0\": X0}\n",
    "    exec(scene[\"SimplicitObjects\"][0][\"SetFixedBC_code\"], globals(), l_dict)\n",
    "    indices = l_dict[\"indices\"]\n",
    "    indices = (3*indices).repeat_interleave(3)\n",
    "    indices[1::3] += 1\n",
    "    indices[2::3] += 2; \n",
    "    # Create a mask to identify rows to be removed; \n",
    "    mask[indices] = True\n",
    "    \n",
    "    #### Create an nxn identity matrix\n",
    "    Id = torch.eye(num_samples*3)\n",
    "    # Use the mask to remove rows from the identity matrix\n",
    "    redID = Id[mask]\n",
    "    J = redID.T.to(device)\n",
    "\n",
    "    # 2*num samples gravities per sample point\n",
    "    grav = torch.zeros(num_samples*3).to(device)\n",
    "    grav[0::3] = float(scene[\"Gravity\"][0]) #acc from gravity\n",
    "    grav[1::3] = float(scene[\"Gravity\"][1]) #acc from gravity\n",
    "    grav[2::3] = float(scene[\"Gravity\"][2]) #acc from gravity\n",
    "    \n",
    "    \n",
    "    #total mass of object\n",
    "    density_m = torch.tensor(np_Rho, dtype=torch.float32, device=device) #kg/m^2\n",
    "    sample_vol = np_object[\"ObjectVol\"]/density_m.shape[0]\n",
    "    \n",
    "    #mass matrix created  from masses assuming uniform density over mesh\n",
    "    m = density_m*sample_vol#torch.sum((total_m/W.shape[0])*W, dim=1).to(device)\n",
    "    M = torch.diag(m.repeat_interleave(3)).to(device).float()\n",
    "\n",
    "    #total mass of object\n",
    "    # density_m = float(10) #kg/m^2\n",
    "    # total_m = density_m*np_object[\"ObjectVol\"]\n",
    "    \n",
    "    # #mass matrix created  from masses assuming uniform density over mesh\n",
    "    # m = (total_m/X0.shape[0])*torch.ones(X0.shape[0], dtype=torch.float32, device=device)#torch.sum((total_m/W.shape[0])*W, dim=1).to(device)\n",
    "    # M = torch.diag(m.repeat_interleave(3)).to(device).float()\n",
    "        \n",
    "    # affine dofs and velocities\n",
    "    z = torch.tensor([[0,0,0,0],[0,0,0,0],[0,0,0,0]], dtype=torch.float32, requires_grad=True, device=device).flatten().repeat(num_handles).unsqueeze(-1)\n",
    "    z_dot = torch.zeros_like(z).to(device)\n",
    "\n",
    "    # 3*samples x 4*3*handles\n",
    "    X03 = torch.cat((X0, torch.ones(X0.shape[0], device=device).unsqueeze(-1)), dim=1)\n",
    "    X03reps = X03.repeat_interleave(3, dim=0).repeat((1, 3*num_handles))\n",
    "    Wreps = W.repeat_interleave(12, dim=1).repeat_interleave(3, dim=0)\n",
    "    WX03reps = torch.mul(Wreps, X03reps)\n",
    "    Bsetup = torch.kron(torch.ones(num_samples).unsqueeze(-1), torch.eye(3)).repeat((1,num_handles)).to(device)\n",
    "    Bmask = torch.repeat_interleave(Bsetup, 4, dim=1).to(device)\n",
    "\n",
    "    B = torch.mul(Bmask, WX03reps)\n",
    "\n",
    "    x0_flat = (X0.flatten().unsqueeze(-1))\n",
    "\n",
    "    BMB = B.T@M@B\n",
    "    BJMJB = BMB #B.T@J@J.T@M@J@J.T@B\n",
    "\n",
    "    Mg = M@grav\n",
    "    states.append(z.clone().cpu().detach())\n",
    "\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "\n",
    "    for step in range(int(scene[\"Steps\"])):\n",
    "        # set u prev at start of step\n",
    "        z_prev = z.clone().detach()\n",
    "\n",
    "        barrier_T = 0\n",
    "        for barrier_its in range(int(scene[\"BarrierIts\"])):\n",
    "            for iter in range(int(scene[\"NewtonIts\"])):\n",
    "                # zero out the gradients of u\n",
    "                z.grad = None\n",
    "\n",
    "                def partial_newton_E(z): \n",
    "                    newx = B@z + x0_flat\n",
    "                    PE = potential_energy(Phi,W, z, newx, Mg, X0, tFaces, tYMs, x0_flat, J, B, Handles)\n",
    "                    return 0.5*z.T@BJMJB@z - z.T@BJMJB@ z_prev - dt*z.T@BJMJB@ z_dot + dt*dt*PE\n",
    "\n",
    "                \n",
    "                # Newton's method minimizes this energy\n",
    "                newton_E = partial_newton_E(z)\n",
    "                newton_gradE = torch.autograd.grad(newton_E, inputs = z, allow_unused=True)\n",
    "\n",
    "                newton_hessE = torch.autograd.functional.hessian(partial_newton_E, inputs = z)\n",
    "\n",
    "                # 18885544732 PEC\n",
    "                # print(newton_E)\n",
    "                # print(newton_gradE)\n",
    "                # print(torch.sum(newton_hessE))\n",
    "                with torch.no_grad():\n",
    "                    newton_H = newton_hessE[:,0,:,0]\n",
    "\n",
    "                    if bool(scene[\"HessianSPDFix\"]):\n",
    "                        # Simple PSD fix\n",
    "                        L, V = torch.linalg.eig(newton_H)\n",
    "                        L = torch.real(L)\n",
    "                        L[L<1e-2] = 1e-2\n",
    "                        L = torch.complex(L, torch.zeros_like(L))\n",
    "                        fixed_H = torch.real(V@torch.diag(L)@torch.linalg.inv(V))\n",
    "                    else:\n",
    "                        fixed_H = newton_H\n",
    "                \n",
    "                    # print(step, torch.dist(fixed_H, newton_H))\n",
    "\n",
    "                    newton_g = torch.cat(newton_gradE)\n",
    "                    newx = B@z + x0_flat\n",
    "                    # Solve for x using J and g\n",
    "                    dz = -torch.linalg.solve(fixed_H[:, :], newton_g[:])\n",
    "\n",
    "                    print(torch.norm(newton_g))\n",
    "                    if (torch.norm(newton_g)<2e-4):\n",
    "                        print(\"-----------Converged\")\n",
    "                        break\n",
    "                    \n",
    "                    # Line Search\n",
    "                    alpha = line_search(partial_newton_E, z, dz, newton_g)\n",
    "        \n",
    "                    print(\"ls alpha: \", alpha)\n",
    "                    # Update positions \n",
    "                    z[:] += alpha*dz\n",
    "\n",
    "            with torch.no_grad():\n",
    "                z_dot = (z - z_prev)/dt\n",
    "\n",
    "            barrier_T += 1\n",
    "        states.append(z.clone().cpu().detach())\n",
    "        simulation_iteration += 1\n",
    "        torch.save(states, name_and_training_dir+\"/\" + scene_name + \"-sim_states\")\n",
    "\n",
    "    return states, X0.cpu().detach(), W.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b27847f4-93df-4951-b0e5-182950bba19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scene = json.loads(open(f'scenes/{scene_name}.json', \"r\").read())\n",
    "\n",
    "t_O = torch.tensor(np_object[\"ObjectSamplePts\"], dtype=torch.float32).to(device)\n",
    "# t_YMs = torch.tensor(np_object[\"ObjectYMs\"], dtype=torch.float32).to(device)\n",
    "# t_Rho = torch.tensor(np_object[\"ObjectRho\"], dtype=torch.float32).to(device)\n",
    "simulation_iteration = 0\n",
    "barrier_T = 0\n",
    "\n",
    "#timestep \n",
    "dt = float(scene[\"dt\"]) #s\n",
    "move_mask = None\n",
    "explicit_W = None # torch.tensor(np_object[\"biharmonic_weights\"]).float().to(device)#Handles.getAllWeightsSoftmax(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c77a150-0009-43b8-91aa-d63d832ae4e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0996, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0374, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0140, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0053, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0020, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0002, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.1319, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0494, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0185, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0070, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(9.1642e-05, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.1893, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0710, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0266, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0100, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0037, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0014, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0002, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.2458, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0922, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0346, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0130, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0002, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.2991, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1122, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0421, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0158, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0059, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0022, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0008, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0001, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.3491, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1309, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0491, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0184, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0069, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(9.1114e-05, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.3963, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1486, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0557, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0209, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0078, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0029, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  4.76837158203125e-06\n",
      "tensor(0.4391, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1647, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0617, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0232, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0087, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0033, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  9.5367431640625e-06\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  0.0048828125\n",
      "tensor(0.4798, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1799, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0675, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0253, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0095, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0036, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0013, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0001, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.5167, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1937, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0727, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0272, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0102, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0014, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.5490, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2059, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0772, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0290, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0109, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0001, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.5780, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2168, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0813, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0305, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0114, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0043, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.6024, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2259, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0847, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0318, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0119, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0045, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0008, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.6237, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2339, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0877, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0329, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0123, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0046, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0017, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0008, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.6406, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2402, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0901, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0338, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0127, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0047, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.00244140625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.0048828125\n",
      "tensor(0.6532, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2450, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0919, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0345, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0129, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0048, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  10.0\n",
      "tensor(0.0027, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.6607, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2478, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0929, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0348, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0131, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0001, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.6651, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2494, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0935, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0351, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0132, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.00244140625\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.6632, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2487, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0933, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0350, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0131, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.0006103515625\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.00030517578125\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.6614, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2481, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0930, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0349, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0131, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.0006103515625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0013, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.6569, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2464, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0924, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0346, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0130, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  0.000152587890625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  0.00244140625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.6491, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2434, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0913, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0342, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0128, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0048, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.6410, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2404, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0901, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0338, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0127, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0048, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.0046, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0017, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.000152587890625\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.6300, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2363, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0886, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0332, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0125, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0047, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0003, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0012, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.6191, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2322, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0871, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0326, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0122, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0046, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0017, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0018, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0017, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.6068, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2276, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0853, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0320, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0120, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0045, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0017, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.5941, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2228, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0836, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0313, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0117, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0044, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0008, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.009765625\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.5825, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2185, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0819, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0307, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0115, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0043, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5707, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2140, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0803, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0301, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0113, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0042, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0002, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.5597, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2099, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0787, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0295, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0111, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0042, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0042, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0042, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.5483, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2056, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0771, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0289, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0108, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  0.00244140625\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0027, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0027, device='cuda:0')\n",
      "ls alpha:  9.5367431640625e-06\n",
      "tensor(0.5362, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2011, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0754, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0283, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0106, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0104, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.0104, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.0104, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0104, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.0100, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.5241, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1966, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0737, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0276, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0104, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0039, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0022, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5165, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1937, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0726, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0272, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0102, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0035, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0036, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0013, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5111, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1917, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0719, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0270, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0101, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  7.62939453125e-05\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.5076, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1904, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0714, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0268, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0100, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0022, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5051, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1894, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0710, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0266, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0100, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0037, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0014, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0005, device='cuda:0')\n",
      "ls alpha:  10.0\n",
      "tensor(0.0047, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.5083, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1906, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0715, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0268, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0101, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0025, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0001, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.5082, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1906, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0715, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0268, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0101, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0032, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0008, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0007, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0002, device='cuda:0')\n",
      "-----------Converged\n",
      "tensor(0.5093, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1910, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0716, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0269, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0101, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0009, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.001220703125\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0035, device='cuda:0')\n",
      "ls alpha:  0.00030517578125\n",
      "tensor(0.5086, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1907, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0715, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0268, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0101, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0038, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0014, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0021, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0021, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.0020, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.5140, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1928, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0723, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0271, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0102, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0025, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0025, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.0006, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.5188, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1946, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0730, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0274, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0103, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0039, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0058, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0049, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  0.01953125\n",
      "tensor(0.5295, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.1986, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0745, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0279, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0105, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0026, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0039, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.0048828125\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5372, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2014, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0755, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0283, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0106, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0027, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0040, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0013, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0011, device='cuda:0')\n",
      "ls alpha:  0.0390625\n",
      "tensor(0.5450, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2043, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0766, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0287, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0108, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0040, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.0061, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0023, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0034, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.5554, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2083, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0781, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0293, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0110, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0027, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.0041, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0015, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0004, device='cuda:0')\n",
      "ls alpha:  5.0\n",
      "tensor(0.5641, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2115, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0793, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0297, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0112, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0042, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0016, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0014, device='cuda:0')\n",
      "ls alpha:  0.3125\n",
      "tensor(0.0010, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.5743, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2154, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0808, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0303, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0114, device='cuda:0')\n",
      "ls alpha:  1.25\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  1.9073486328125e-05\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  9.5367431640625e-06\n",
      "tensor(0.0028, device='cuda:0')\n",
      "ls alpha:  9.5367431640625e-06\n",
      "tensor(0.5880, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.2205, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0827, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0310, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0116, device='cuda:0')\n",
      "ls alpha:  0.078125\n",
      "tensor(0.0107, device='cuda:0')\n",
      "ls alpha:  0.625\n",
      "tensor(0.0040, device='cuda:0')\n",
      "ls alpha:  2.5\n",
      "tensor(0.0060, device='cuda:0')\n",
      "ls alpha:  0.15625\n",
      "tensor(0.0051, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n",
      "tensor(0.0051, device='cuda:0')\n",
      "ls alpha:  3.814697265625e-05\n"
     ]
    }
   ],
   "source": [
    "if run_simulation:\n",
    "    random_batch_indices = np.random.randint(0, np_object[\"ObjectSamplePts\"].shape[0], size=int(scene[\"NumCubaturePts\"])) \n",
    "    np_V = None #np_object[\"surfV\"][:, 0:3]\n",
    "    np_F = 0 #np_object[\"surfF\"]\n",
    "    np_X = np_object[\"ObjectSamplePts\"][:, 0:3][random_batch_indices, :]\n",
    "    np_YMs = np_object[\"ObjectYMs\"][random_batch_indices, np.newaxis]\n",
    "    np_Rho = np_object[\"ObjectRho\"][random_batch_indices, np.newaxis]\n",
    "    np_PRs = np_object[\"ObjectPRs\"][random_batch_indices, np.newaxis]\n",
    "    torch.save(np_X, name_and_training_dir+\"/\" + scene_name + \"-sim_X0\")\n",
    "    torch.save(np_YMs, name_and_training_dir+\"/\" + scene_name + \"-sim_W\")\n",
    "    \n",
    "    states,  t_X0, explicit_W = simulate(np_X, np_F, np_YMs, np_PRs, np_Rho, explicit_W, E_pot, Handles_post)\n",
    "    \n",
    "    torch.save(states, name_and_training_dir+\"/\" + scene_name + \"-sim_states\")\n",
    "    torch.save(t_X0, name_and_training_dir+\"/\" + scene_name + \"-sim_X0\")\n",
    "    torch.save(explicit_W, name_and_training_dir+\"/\" + scene_name + \"-sim_W\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c509f971-8756-4275-a6dd-c8b002038415",
   "metadata": {},
   "source": [
    "## 6. Animate with Polyscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5727c6cd-4381-461b-a349-d80d2a2fd34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "loaded_Handles = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_post\",  map_location=torch.device(device))\n",
    "loaded_X0 = torch.tensor(np_object[\"ObjectSamplePts\"],  dtype=torch.float32)\n",
    "# loaded_X0 = torch.load(object_name+\"/\"+training_name+\"-training\" +\"/\"+str(args[2])+\"-sim_X0\", map_location=torch.device(device))\n",
    "loaded_ym = torch.tensor(np_object[\"ObjectYMs\"]).detach().numpy()\n",
    "# loaded_ym = torch.ones(loaded_X0.shape[0])\n",
    "loaded_states = torch.load(object_name+\"/\"+training_name+\"-training\" +\"/\"+f\"{scene_name}-sim_states\", map_location=torch.device(device))\n",
    "\n",
    "showPointcloud = True\n",
    "showUniformSample = True \n",
    "showReconstruction = False\n",
    "\n",
    "def getX(Ts, l_X0, l_W):\n",
    "    def x(x0, tW):\n",
    "        x0_i = x0.unsqueeze(0)\n",
    "        x03 = torch.cat((x0_i, torch.tensor([[1]], device=device)), dim=1)\n",
    "        Ws = tW.T\n",
    "        \n",
    "        def inner_over_handles(T, w):\n",
    "            return w*T@x03.T\n",
    "\n",
    "        wTx03s = torch.vmap(inner_over_handles)(Ts.to(device), Ws)\n",
    "        x_i =  torch.sum(wTx03s, dim=0)\n",
    "        return x_i.T + x0_i\n",
    "    \n",
    "    X = torch.vmap(x, randomness=\"same\")(l_X0.to(device), l_W.to(device))\n",
    "    return X[:,0,:].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "frame_num = 0\n",
    "if show_plot:\n",
    "    ps.init()\n",
    "    \n",
    "    #set bounding box for floor plane and scene extents\n",
    "    ps.set_automatically_compute_scene_extents(False)\n",
    "    ps.set_length_scale(1.)\n",
    "    low = np.array((float(scene[\"BoundingX\"][0]), \n",
    "                    float(scene[\"BoundingY\"][0]), \n",
    "                    float(scene[\"BoundingZ\"][0]))) \n",
    "    \n",
    "    high = np.array((float(scene[\"BoundingX\"][1]), \n",
    "                     float(scene[\"BoundingY\"][1]), \n",
    "                     float(scene[\"BoundingZ\"][1])))\n",
    "    ps.set_bounding_box(low, high)\n",
    "    ps.set_ground_plane_height_factor(-float(scene[\"Floor\"]) + float(scene[\"BoundingY\"][0]), is_relative=False) # adjust the plane height\n",
    "    \n",
    "    \n",
    "    ps_cloud = ps.register_point_cloud(\"samples\", loaded_X0.cpu().numpy(), enabled=True)\n",
    "    ps_cloud.add_scalar_quantity(\"yms\", loaded_ym, enabled=True)\n",
    "\n",
    "\n",
    "if (len(scene[\"CollisionObjects\"])>0):\n",
    "    pokes = np.zeros((len(scene[\"CollisionObjects\"]), 3))\n",
    "    rad = scene[\"CollisionObjects\"][0][\"Radius\"]\n",
    "    for p in range(len(scene[\"CollisionObjects\"])):\n",
    "        collision_object = torch.tensor(scene[\"CollisionObjects\"][p][\"Position\"], dtype=torch.float32, device=device)\n",
    "        pokes[p,:] = collision_object\n",
    "    ps_pokes = ps.register_point_cloud(\"Pokes\", pokes, radius=rad, enabled=True)\n",
    "\n",
    "\n",
    "computed_W_X0 =  torch.cat((loaded_Handles.getAllWeightsSoftmax(loaded_X0), torch.ones(loaded_X0.shape[0], 1)), dim=1) \n",
    "\n",
    "def callback():\n",
    "   global frame_num, loaded_states, computed_W, loaded_all, ps_cloud, ps_surf#, ps_vol#, ps_surf\n",
    "   changed, frame_num = psim.SliderInt(\"Frame\", frame_num, v_min=0, v_max=len(loaded_states)-1)\n",
    "   if changed:\n",
    "      Ts = loaded_states[frame_num].reshape(-1, 3,4)\n",
    "      X = getX(Ts, loaded_X0, computed_W_X0)\n",
    "      ps_cloud.update_point_positions(X)\n",
    "\n",
    "      if (len(scene[\"CollisionObjects\"])>0):\n",
    "        for p in range(len(scene[\"CollisionObjects\"])):\n",
    "                collision_object = np.array(scene[\"CollisionObjects\"][p][\"Position\"])\n",
    "                l_dict = {\"collision_obj\" : collision_object, \"dt\" : 0.1, \"simulation_iteration\" : frame_num}\n",
    "                exec(scene[\"CollisionObjects\"][p][\"Update_code\"], None, l_dict)\n",
    "                collision_object = l_dict[\"pos\"]\n",
    "                pokes[p,:] = collision_object\n",
    "        ps_pokes.update_point_positions(pokes)\n",
    "\n",
    "\n",
    "if show_plot:\n",
    "    ps.set_user_callback(callback)\n",
    "    ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5410f33d-f7f9-47ac-ba74-358d3ab45ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ts.shape, loaded_X0.shape, computed_W_X0.shape, loaded_x0.shape, computed_w_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03ca5889-724b-40b1-8dae-e192b103bd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cpu\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "loaded_Handles = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_post\",  map_location=torch.device(device))\n",
    "loaded_X0 = gaussians.get_xyz.to(device).to(torch.float32)\n",
    "loaded_R = gaussians._rotation.to(device).to(torch.float32)  # Pre activation: normalize, Quaternion of shape (N, 4)\n",
    "loaded_S = gaussians._scaling.to(device).to(torch.float32)   # Pre activation: exp, Vec3 of shape (N, 3)\n",
    "loaded_ym = torch.tensor(np_object[\"ObjectYMs\"]).detach().numpy()\n",
    "\n",
    "# List at length (num_frames)\n",
    "# Each entry is a flattened tensor of (num_handles, 3, 4)\n",
    "loaded_states = torch.load(object_name+\"/\"+training_name+\"-training\" +\"/\"+f\"{scene_name}-sim_states\", map_location=torch.device(device))\n",
    "\n",
    "def getX(Ts, l_X0, l_W):\n",
    "    def x(x0, tW):\n",
    "        x0_i = x0.unsqueeze(0)  # -> Shape (1, 3)\n",
    "        x03 = torch.cat((x0_i, torch.tensor([[1]], device=device)), dim=1) # Shape (1, 4)\n",
    "        Ws = tW.T # Shape (num_handles + 1,)\n",
    "        \n",
    "        def inner_over_handles(T, w):\n",
    "            return w*T@x03.T\n",
    "\n",
    "        wTx03s = torch.vmap(inner_over_handles)(Ts.to(device), Ws)\n",
    "        x_i =  torch.sum(wTx03s, dim=0)\n",
    "        return x_i.T + x0_i\n",
    "    \n",
    "    X = torch.vmap(x, randomness=\"same\")(l_X0.to(device), l_W.to(device))\n",
    "    return X[:,0,:].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "frame_num = 0\n",
    "\n",
    "if (len(scene[\"CollisionObjects\"])>0):\n",
    "    pokes = np.zeros((len(scene[\"CollisionObjects\"]), 3))\n",
    "    rad = scene[\"CollisionObjects\"][0][\"Radius\"]\n",
    "    for p in range(len(scene[\"CollisionObjects\"])):\n",
    "        collision_object = torch.tensor(scene[\"CollisionObjects\"][p][\"Position\"], dtype=torch.float32, device=device)\n",
    "        pokes[p,:] = collision_object\n",
    "\n",
    "# computed_W_X0 is ~(num_gaussians, num_handles + 1), representing the weight each handle assigns to each point\n",
    "computed_W_X0 =  torch.cat((loaded_Handles.getAllWeightsSoftmax(loaded_X0), torch.ones(loaded_X0.shape[0], 1)), dim=1) \n",
    "\n",
    "\n",
    "def callback():\n",
    "   global frame_num, loaded_states, computed_W, loaded_all, ps_cloud, ps_surf#, ps_vol#, ps_surf\n",
    "   changed, frame_num = psim.SliderInt(\"Frame\", frame_num, v_min=0, v_max=len(loaded_states)-1)\n",
    "   if changed:\n",
    "      Ts = loaded_states[frame_num].reshape(-1, 3,4)\n",
    "      X = getX(Ts, loaded_X0, computed_W_X0)\n",
    "      ps_cloud.update_point_positions(X)\n",
    "\n",
    "      if (len(scene[\"CollisionObjects\"])>0):\n",
    "        for p in range(len(scene[\"CollisionObjects\"])):\n",
    "                collision_object = np.array(scene[\"CollisionObjects\"][p][\"Position\"])\n",
    "                l_dict = {\"collision_obj\" : collision_object, \"dt\" : 0.1, \"simulation_iteration\" : frame_num}\n",
    "                exec(scene[\"CollisionObjects\"][p][\"Update_code\"], None, l_dict)\n",
    "                collision_object = l_dict[\"pos\"]\n",
    "                pokes[p,:] = collision_object\n",
    "        ps_pokes.update_point_positions(pokes)\n",
    "\n",
    "\n",
    "# -- Show in Polyscope --\n",
    "          \n",
    "# ps.init()\n",
    "# #set bounding box for floor plane and scene extents\n",
    "# ps.set_automatically_compute_scene_extents(False)\n",
    "# ps.set_length_scale(1.)\n",
    "# low = np.array((float(scene[\"BoundingX\"][0]), \n",
    "#                 float(scene[\"BoundingY\"][0]), \n",
    "#                 float(scene[\"BoundingZ\"][0]))) \n",
    "\n",
    "# high = np.array((float(scene[\"BoundingX\"][1]), \n",
    "#                  float(scene[\"BoundingY\"][1]), \n",
    "#                  float(scene[\"BoundingZ\"][1])))\n",
    "# ps.set_bounding_box(low, high)\n",
    "# ps.set_ground_plane_height_factor(-float(scene[\"Floor\"]) + float(scene[\"BoundingY\"][0]), is_relative=False) # adjust the plane height\n",
    "\n",
    "\n",
    "# ps_cloud = ps.register_point_cloud(\"samples\", loaded_X0.cpu().detach().numpy(), enabled=True)\n",
    "# ps.set_user_callback(callback)\n",
    "# ps.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebe4472a-58e3-45b0-b92e-9d109978de52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2730223/2810611361.py:16: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1682343998658/work/aten/src/ATen/native/TensorShape.cpp:3571.)\n",
      "  Ws = tW.T # Shape (num_handles + 1,)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6d5c4d84a94db09969431c03b0a2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=512, width=512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9989c484f7184b048e826408e727d007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Time', layout=Layout(width='1000px'), max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb6dee62e7446deacd29301c3a0b33b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(-10.353991508483887, -0.8916848301887512), description='Log Scale:', layout=Layout(wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a039a1502f1d4aae8d1fc54c88d98b9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatRangeSlider(value=(0.0010375179117545485, 1.0), description='Opacity:', layout=Layout(width='1000px'), ma…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fecd95ec8ee4b248a2dba8288215b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='SH+-', layout=Layout(width='1000px'), max=2.0, readout_format='.3f', step=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae0c07d24d2491abbb3d6454f29601b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatSlider(value=1.0, description='Rescale', layout=Layout(width='1000px'), max=10.0, min=0.001, readout_form…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets\n",
    "from ipywidgets import Layout\n",
    "import kaolin\n",
    "from thirdparty.gausplat.gaussian_renderer import render, GaussianModel\n",
    "from gaussian_splat_utils import convert_kaolin_camera\n",
    "\n",
    "gaussians = load_checkpoint(OUTPUT_FOLDER)\n",
    "camera = try_load_kaolin_camera(OUTPUT_FOLDER)\n",
    "renderer = GaussianSplatsRendererSetup(gaussians, camera)\n",
    "time_slider = ipywidgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, max=50.0,\n",
    "    step=1,\n",
    "    description=f'Time',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    # readout_format='.3f',\n",
    "    layout=Layout(width='1000px')\n",
    ")\n",
    "\n",
    "scaling_property = renderer.scaling_property\n",
    "opacity_property = renderer.opacity_property\n",
    "scaling_slider = renderer.scaling_slider\n",
    "opacity_slider = renderer.opacity_slider\n",
    "attenuate_slider = renderer.attenuate_slider\n",
    "rescale_slider = renderer.rescale_slider\n",
    "pipeline = renderer.pipeline\n",
    "background = renderer.background\n",
    "\n",
    "\n",
    "def timed_render_kaolin(kaolin_cam):\n",
    "    \"\"\"Same rendering as above, but we subsample gaussians based on their scale.\"\"\"\n",
    "    # Select only the gaussians with radius below value\n",
    "    frame_num = time_slider.value\n",
    "    Ts = loaded_states[frame_num].reshape(-1, 3,4)\n",
    "    X = getX(Ts, loaded_X0, computed_W_X0)\n",
    "    \n",
    "    scale_min_mask = scaling_property.min(dim=1)[0] > scaling_slider.value[0]\n",
    "    scale_max_mask = scaling_property.max(dim=1)[0] < scaling_slider.value[1]\n",
    "    scale_mask = scale_min_mask & scale_max_mask\n",
    "    opacity_min_mask = opacity_property.min(dim=1)[0] > opacity_slider.value[0]\n",
    "    opacity_max_mask = opacity_property.max(dim=1)[0] < opacity_slider.value[1]\n",
    "    opacity_mask = opacity_min_mask & opacity_max_mask\n",
    "    mask = scale_mask & opacity_mask\n",
    "    tmp_gaussians = GaussianModel(gaussians.max_sh_degree)\n",
    "    tmp_gaussians._xyz = torch.from_numpy(X).cuda()[mask, :]\n",
    "    tmp_gaussians._features_dc = gaussians._features_dc[mask, ...]\n",
    "    tmp_gaussians._features_rest = gaussians._features_rest[mask, ...] * attenuate_slider.value\n",
    "    tmp_gaussians._opacity = gaussians._opacity[mask, ...]\n",
    "    tmp_gaussians._scaling = gaussians._scaling[mask, ...] * rescale_slider.value\n",
    "    tmp_gaussians._rotation = gaussians._rotation[mask, ...]\n",
    "    tmp_gaussians.active_sh_degree = gaussians.max_sh_degree\n",
    "\n",
    "    cam = convert_kaolin_camera(kaolin_cam)\n",
    "    render_res = render(cam, tmp_gaussians, pipeline, background)\n",
    "    rendering = render_res[\"render\"]\n",
    "    return (rendering.permute(1, 2, 0) * 255).to(torch.uint8).detach().cpu()\n",
    "\n",
    "def handle_slider(e):\n",
    "    renderer.visualizer.out.clear_output()\n",
    "    with renderer.visualizer.out:\n",
    "        renderer.visualizer.render_update()\n",
    "\n",
    "# Instantiate visualizer with this custom render function\n",
    "camera.change_coordinate_system(\n",
    "    torch.tensor(\n",
    "        [[1, 0, 0],\n",
    "         [0, 0, 1],\n",
    "         [0, -1, 0]])\n",
    ")\n",
    "# pitch=np.pi/2, yaw=np.pi/2\n",
    "# camera.rotate(roll=np.pi/8)\n",
    "focus_at = (camera.cam_pos() - 4. * camera.extrinsics.cam_forward()).squeeze()\n",
    "renderer.visualizer = kaolin.visualize.IpyTurntableVisualizer(\n",
    "    512, 512, copy.deepcopy(camera), timed_render_kaolin,\n",
    "    focus_at=focus_at, world_up_axis=1, max_fps=12)\n",
    "renderer.visualizer.render_update()\n",
    "\n",
    "scaling_slider.observe(handle_slider, names='value')\n",
    "opacity_slider.observe(handle_slider, names='value')\n",
    "attenuate_slider.observe(handle_slider, names='value')\n",
    "rescale_slider.observe(handle_slider, names='value')\n",
    "time_slider.observe(handle_slider, names='value')\n",
    "\n",
    "display(\n",
    "    renderer.visualizer.canvas,\n",
    "    time_slider,\n",
    "    # renderer.visualizer.out,\n",
    "    renderer.scaling_slider,\n",
    "    renderer.opacity_slider,\n",
    "    renderer.attenuate_slider,\n",
    "    renderer.rescale_slider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "43846c50-75a6-4de5-8af7-c65cde0d4689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def getX_cov(Ts, l_X0, l_W):\n",
    "#     def x(x0, tW):\n",
    "#         x0_i = x0.unsqueeze(0)\n",
    "#         x03 = torch.cat((x0_i, torch.tensor([[1]], device=device)), dim=1)\n",
    "#         Ws = tW.T\n",
    "        \n",
    "#         def inner_over_handles(T, w):\n",
    "#             return w*T@x03.T\n",
    "\n",
    "#         wTx03s = torch.vmap(inner_over_handles)(Ts.to(device), Ws)\n",
    "#         x_i =  torch.sum(wTx03s, dim=0)\n",
    "#         return x_i.T + x0_i\n",
    "    \n",
    "#     X = torch.vmap(x, randomness=\"same\")(l_X0.to(device), l_W.to(device))\n",
    "#     return X[:,0,:].cpu().detach().numpy()\n",
    "\n",
    "\n",
    "frame_num = 20\n",
    "Ts = loaded_states[frame_num].reshape(-1, 3,4)  # (num_handles+1, 3, 4)\n",
    "l_X0 = loaded_X0\n",
    "l_W = computed_W_X0\n",
    "x0 = l_X0[0]\n",
    "tW = l_W[0]\n",
    "\n",
    "x0_i = x0.unsqueeze(0) # Shape (1, 3)\n",
    "x03 = torch.cat((x0_i, torch.tensor([[1]], device=device)), dim=1) # (1, 4)\n",
    "Ws = tW.T # Shape ~ (num_handles + 1,)\n",
    "\n",
    "\n",
    "# def inner_over_handles(T, w):\n",
    "#     return w*T@x03.T\n",
    "# wTx03s = torch.vmap(inner_over_handles)(Ts.to(device), Ws)  # (num_handles+1, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "127ba2e7-c547-4eae-a84a-2313f4075695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def to_scale_matrix(v):\n",
    "#     \"\"\" vec3 to scale matrix \"\"\"\n",
    "#     S = torch.zeros((v.shape[0], 3, 3), dtype=v.dtype, device=v.device)\n",
    "#     S[:,0,0] = v[:,0]\n",
    "#     S[:,1,1] = v[:,1]\n",
    "#     S[:,2,2] = v[:,2]\n",
    "#     return S\n",
    "\n",
    "\n",
    "# def decompose(transforms):\n",
    "#     U, S, Vt = torch.linalg.svd(transforms, full_matrices=False)\n",
    "#     L = to_scale_matrix(S)\n",
    "#     return U, L, Vt[:,:,:3]\n",
    "    \n",
    "\n",
    "# def to_rotation_matrix(r):\n",
    "#     norm = torch.sqrt(r[:,0]*r[:,0] + r[:,1]*r[:,1] + r[:,2]*r[:,2] + r[:,3]*r[:,3])\n",
    "\n",
    "#     q = r / norm[:, None]\n",
    "\n",
    "#     R = torch.zeros((q.size(0), 3, 3), device='cuda')\n",
    "\n",
    "#     r = q[:, 0]\n",
    "#     x = q[:, 1]\n",
    "#     y = q[:, 2]\n",
    "#     z = q[:, 3]\n",
    "\n",
    "#     R[:, 0, 0] = 1 - 2 * (y*y + z*z)\n",
    "#     R[:, 0, 1] = 2 * (x*y - r*z)\n",
    "#     R[:, 0, 2] = 2 * (x*z + r*y)\n",
    "#     R[:, 1, 0] = 2 * (x*y + r*z)\n",
    "#     R[:, 1, 1] = 1 - 2 * (x*x + z*z)\n",
    "#     R[:, 1, 2] = 2 * (y*z - r*x)\n",
    "#     R[:, 2, 0] = 2 * (x*z - r*y)\n",
    "#     R[:, 2, 1] = 2 * (y*z + r*x)\n",
    "#     R[:, 2, 2] = 1 - 2 * (x*x + y*y)\n",
    "#     return R\n",
    "\n",
    "\n",
    "# def matrix_to_quaternion(R):\n",
    "#     tr = R[:, 0, 0] + R[:, 1, 1] + R[:, 2, 2]\n",
    "#     qw = torch.sqrt(1 + tr) / 2\n",
    "#     qx = (R[:, 2, 1] - R[:, 1, 2]) / (4 * qw)\n",
    "#     qy = (R[:, 0, 2] - R[:, 2, 0]) / (4 * qw)\n",
    "#     qz = (R[:, 1, 0] - R[:, 0, 1]) / (4 * qw)\n",
    "#     quaternion = torch.stack([qw, qx, qy, qz], dim=-1)\n",
    "#     return quaternion\n",
    "\n",
    "# def diag_matrix_to_vec3(D):\n",
    "#     \"\"\" (N, 3, 3) -> (N, 1, 3) \"\"\"\n",
    "#     return torch.cat([D[:, 0, 0], D[:, 1, 1], D[:, 2, 2]]).unsqueeze(0)\n",
    "\n",
    "# def normalize_doublecover(Q):\n",
    "#     \"\"\"\n",
    "#     Handles the quaternions double cover issue, where q=-q represents the same rotation.\n",
    "#     Instead we pick the first rotation as a pivot, and make sure all subsequent quaternions are positively oriented with it\n",
    "#     (e.g:   dot(q0, qi) > 0.0 for i~[1,N]    )\n",
    "#     \"\"\"\n",
    "#     Q_mask = 1.0 - (Q @ Q[0] < 0.0).int() * 2.0\n",
    "#     Q_normalized = Q_mask[:,None] * Q\n",
    "#     return Q_normalized\n",
    "\n",
    "# def weighted_quaternions(Q, w):\n",
    "#     # See: https://math.stackexchange.com/questions/61146/averaging-quaternions\n",
    "#     # The current solution is a fast approximation and breaks if the quaternions are not similar enough\n",
    "#     Q = normalize_doublecover(Q)\n",
    "#     return (w * Q).sum(dim=0)\n",
    "\n",
    "# def transform_cov(U, L, Vt, R, S):\n",
    "#     R_mat = to_rotation_matrix(R)\n",
    "#     transformed_S = L @ S\n",
    "#     transformed_R = U @ R_mat @ Vt\n",
    "#     transformed_R = to_quaternion(transformed_R)\n",
    "#     return transformed_R, transformed_S\n",
    "\n",
    "\n",
    "# def get_cov_factorized(Ts, l_R, l_S, l_W):\n",
    "#     \"\"\"\n",
    "#     Ts: (H, 3, 4) - affine transform per handle\n",
    "#     l_R: (N, 4) - rotation quaternion per gaussian\n",
    "#     l_S: (N, 3) - scale vector per gaussian\n",
    "#     l_W: (N, H) - weight per gaussian, per handle\n",
    "#     \"\"\"\n",
    "#     # Affine transformations to rotational and scale components (ignore translational component)\n",
    "#     # U: (H, 3, 3)\n",
    "#     # L: (H, 3, 3)\n",
    "#     # Vt: (H, 3, 3)  (positional part trimmed)\n",
    "#     U, L, Vt = decompose(Ts)\n",
    "#     def cov(r_mat, s_mat, Ws):\n",
    "#         # Ws: (H,)\n",
    "#         r_i = r_mat.unsqueeze(0) # r_i: (1, 3, 3)\n",
    "#         s_i = s_mat.unsqueeze(0) # s_i: (1, 3, 3)\n",
    "        \n",
    "#         def inner_over_handles(u, l, vt, w):\n",
    "#             transformed_S = w * l @ s_i\n",
    "#             transformed_S = diag_matrix_to_vec3(transformed_S)\n",
    "#             transformed_R = u @ r_i @ vt  # will be weighted when the gaussians are averaged\n",
    "#             transformed_Q = matrix_to_quaternion(transformed_R)\n",
    "#             return transformed_Q, transformed_S\n",
    "\n",
    "#         # w_Q_tag: (H, 1, 4)\n",
    "#         # w_S_tag: (H, 1, 3)\n",
    "#         w_Q_tag, w_S_tag = torch.vmap(inner_over_handles)(U.to(device), L.to(device), Vt.to(device), Ws)\n",
    "\n",
    "#         # weighted_quaternions takes (H, 4) and (H, 1) inputs\n",
    "#         H = U.shape[0]\n",
    "#         # w_Q_tag_i: (4,)\n",
    "#         w_Q_tag_i =  weighted_quaternions(w_Q_tag.squeeze(1), Ws.unsqueeze(1)) / H  # TODO: means don't take the average\n",
    "#         # w_S_tag_i: (3,)\n",
    "#         w_S_tag_i =  torch.sum(w_S_tag, dim=0).squeeze(0) / H\n",
    "#         return w_Q_tag_i, w_S_tag_i\n",
    "\n",
    "#     l_R_mat = to_rotation_matrix(l_R)  # l_R: (N, 3, 3) - rotation matrix per gaussian\n",
    "#     l_S_mat = to_scale_matrix(l_S)     # l_S: (N, 3, 3) - scale matrix per gaussian\n",
    "#     COV_Q, COV_S = torch.vmap(cov, randomness=\"same\")(l_R_mat.to(device), l_S_mat.to(device), l_W.to(device))\n",
    "#     COV_S = gaussians.scaling_inverse_activation(COV_S)\n",
    "#     return COV_Q.cpu().detach().numpy(), COV_S.cpu().detach().numpy()\n",
    "\n",
    "# # Call get_cov with rotation post activation and scale post activation\n",
    "# loaded_R = gaussians.get_rotation.to(device).to(torch.float32)  # Post activation: normalize, Quaternion of shape (N, 4)\n",
    "# loaded_S = gaussians.get_scaling.to(device).to(torch.float32)   # Post activation: exp, Vec3 of shape (N, 3)\n",
    "# cov_q, cov_s = get_cov_factorized(Ts, loaded_R, loaded_S, computed_W_X0)\n",
    "\n",
    "# cov_q, cov_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b992a0a-31ec-4805-b21e-5f825c94378d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_cov(Ts, l_R, l_S, l_W):\n",
    "#     \"\"\"\n",
    "#     Ts: (H, 3, 4) - affine transform per handle\n",
    "#     l_R: (N, 4) - rotation quaternion per gaussian\n",
    "#     l_S: (N, 3) - scale vector per gaussian\n",
    "#     l_W: (N, H) - weight per gaussian, per handle\n",
    "#     \"\"\"\n",
    "#     # Affine transformations to rotational and scale components (ignore translational component)\n",
    "#     # U: (H, 3, 3)\n",
    "#     # L: (H, 3, 3)\n",
    "#     # Vt: (H, 3, 3)  (positional part trimmed)\n",
    "#     U, L, Vt = decompose(Ts)\n",
    "#     def cov(r_mat, s_mat, Ws):\n",
    "#         # Ws: (H,)\n",
    "#         r_i = r_mat.unsqueeze(0) # r_i: (1, 3, 3)\n",
    "#         s_i = s_mat.unsqueeze(0) # s_i: (1, 3, 3)\n",
    "        \n",
    "#         def inner_over_handles(u, l, vt, w):\n",
    "#             transformed_S = w * l @ s_i\n",
    "#             transformed_S = diag_matrix_to_vec3(transformed_S)\n",
    "#             transformed_R = u @ r_i @ vt  # will be weighted when the gaussians are averaged\n",
    "#             transformed_Q = matrix_to_quaternion(transformed_R)\n",
    "#             return transformed_Q, transformed_S\n",
    "\n",
    "#         # w_Q_tag: (H, 1, 4)\n",
    "#         # w_S_tag: (H, 1, 3)\n",
    "#         w_Q_tag, w_S_tag = torch.vmap(inner_over_handles)(U.to(device), L.to(device), Vt.to(device), Ws)\n",
    "\n",
    "#         # weighted_quaternions takes (H, 4) and (H, 1) inputs\n",
    "#         H = U.shape[0]\n",
    "#         # w_Q_tag_i: (4,)\n",
    "#         w_Q_tag_i =  weighted_quaternions(w_Q_tag.squeeze(1), Ws.unsqueeze(1)) / H  # TODO: means don't take the average\n",
    "#         # w_S_tag_i: (3,)\n",
    "#         w_S_tag_i =  torch.sum(w_S_tag, dim=0).squeeze(0) / H\n",
    "#         return w_Q_tag_i, w_S_tag_i\n",
    "\n",
    "#     l_R_mat = to_rotation_matrix(l_R)  # l_R: (N, 3, 3) - rotation matrix per gaussian\n",
    "#     l_S_mat = to_scale_matrix(l_S)     # l_S: (N, 3, 3) - scale matrix per gaussian\n",
    "#     COV_Q, COV_S = torch.vmap(cov, randomness=\"same\")(l_R_mat.to(device), l_S_mat.to(device), l_W.to(device))\n",
    "#     COV_S = gaussians.scaling_inverse_activation(COV_S)\n",
    "#     return COV_Q.cpu().detach().numpy(), COV_S.cpu().detach().numpy()\n",
    "\n",
    "# # Call get_cov with rotation post activation and scale post activation\n",
    "# loaded_R = gaussians.get_rotation.to(device).to(torch.float32)  # Post activation: normalize, Quaternion of shape (N, 4)\n",
    "# loaded_S = gaussians.get_scaling.to(device).to(torch.float32)   # Post activation: exp, Vec3 of shape (N, 3)\n",
    "# cov_q, cov_s = get_cov(Ts, loaded_R, loaded_S, computed_W_X0)\n",
    "\n",
    "# cov_q, cov_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "768e3c95-2a51-4152-97c1-29f58cde276a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gaussians._scaling\n",
    "# U, L, Vt = decompose(Ts)\n",
    "# l_R_mat = to_rotation_matrix(loaded_R)\n",
    "# l_S_mat = to_scale_matrix(loaded_S)\n",
    "# l_W = computed_W_X0\n",
    "\n",
    "# r_mat, s_mat, tW = l_R_mat[0].to(device), l_S_mat[0].to(device), l_W[0].to(device)\n",
    "# r_i = r_mat.unsqueeze(0) # r_i: (1, 3, 3)\n",
    "# s_i = s_mat.unsqueeze(0) # s_i: (1, 3, 3)\n",
    "\n",
    "# u, l, vt, w = U[0].to(device), L[0].to(device), Vt[0].to(device), Ws[0]\n",
    "\n",
    "# transformed_S = w * l @ s_i\n",
    "# transformed_S = diag_matrix_to_vec3(transformed_S)\n",
    "# transformed_R = u @ r_i @ vt  # will be weighted when the gaussians are averaged\n",
    "# transformed_Q = matrix_to_quaternion(transformed_R)\n",
    "\n",
    "# def inner_over_handles(u, l, vt, w):\n",
    "#     transformed_S = w * l @ s_i\n",
    "#     transformed_S = diag_matrix_to_vec3(transformed_S)\n",
    "#     transformed_R = u @ r_i @ vt  # will be weighted when the gaussians are averaged\n",
    "#     transformed_Q = to_quaternion(transformed_R)\n",
    "#     return transformed_Q, transformed_S\n",
    "# w_Q_tag, w_S_tag = torch.vmap(inner_over_handles)(U.to(device), L.to(device), Vt.to(device), Ws)\n",
    "\n",
    "# w_Q_tag_i =  weighted_quaternions(w_Q_tag.squeeze(1), Ws.unsqueeze(1))[None]\n",
    "# w_Q_tag_i.shape\n",
    "\n",
    "# # (A.unsqueeze(1) @ A.unsqueeze(2)).shape\n",
    "# # D_mask = 1.0 - (C @ C[0] < 0.0).int() * 2.0\n",
    "# # D = D_mask[:,None] * C\n",
    "# # (C @ C[0]).min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "fd65a07b-f16d-44e0-bf42-cf349e9d4753",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bdc4b9894bb48c68eebbb45b555f26a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=512, width=512)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14978dcef3e40659edbb6f4a38bdb21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntSlider(value=0, description='Time', layout=Layout(width='1000px'), max=50)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_transforms(g):\n",
    "    device = g._xyz.device\n",
    "    # loaded_states: List at length (num_frames); each entry is a flattened tensor of (num_handles, 3, 4)\n",
    "    loaded_states = torch.load(object_name+\"/\"+training_name+\"-training\" +\"/\"+f\"{scene_name}-sim_states\", map_location=torch.device(device))\n",
    "    num_frames = len(loaded_states)\n",
    "    transforms = torch.stack(loaded_states).reshape(num_frames, -1, 3, 4)  # (num_frames, num_handles+1, 3, 4)\n",
    "    g.transforms = transforms.to(device) # (num_frames, num_handles+1, 3, 4)\n",
    "\n",
    "    # computed_W_X0: tensor of (num_gaussians, num_handles + 1), representing the weight each handle assigns to each point at rest frame\n",
    "    weights =  torch.cat((loaded_Handles.getAllWeightsSoftmax(loaded_X0), torch.ones(loaded_X0.shape[0], 1)), dim=1) \n",
    "    g.weights = weights.to(device)\n",
    "    return g\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import Layout\n",
    "import kaolin\n",
    "from thirdparty.gausplat.gaussian_renderer import render, GaussianModel\n",
    "from gaussian_splat_utils import convert_kaolin_camera\n",
    "\n",
    "device = \"cpu\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "handles_model = torch.load(object_name+\"/\"+training_name+\"-training\" + \"/Handles_post\",  map_location=torch.device(device))\n",
    "gaussians = load_checkpoint(OUTPUT_FOLDER, handles_model=handles_model)\n",
    "gaussians = load_transforms(gaussians)\n",
    "camera = try_load_kaolin_camera(OUTPUT_FOLDER)\n",
    "renderer = GaussianSplatsRendererSetup(gaussians, camera)\n",
    "time_slider = ipywidgets.IntSlider(\n",
    "    value=0,\n",
    "    min=0, max=50.0,\n",
    "    step=1,\n",
    "    description=f'Time',\n",
    "    disabled=False,\n",
    "    continuous_update=True,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    # readout_format='.3f',\n",
    "    layout=Layout(width='1000px')\n",
    ")\n",
    "\n",
    "scaling_property = renderer.scaling_property\n",
    "opacity_property = renderer.opacity_property\n",
    "scaling_slider = renderer.scaling_slider\n",
    "opacity_slider = renderer.opacity_slider\n",
    "attenuate_slider = renderer.attenuate_slider\n",
    "rescale_slider = renderer.rescale_slider\n",
    "pipeline = renderer.pipeline\n",
    "background = renderer.background\n",
    "\n",
    "\n",
    "def timed_render_kaolin(kaolin_cam):\n",
    "    \"\"\"Same rendering as above, but we subsample gaussians based on their scale.\"\"\"\n",
    "    gaussians.keyframe = time_slider.value\n",
    "    cam = convert_kaolin_camera(kaolin_cam)\n",
    "    render_res = render(cam, gaussians, pipeline, background)\n",
    "    rendering = render_res[\"render\"]\n",
    "    return (rendering.permute(1, 2, 0) * 255).to(torch.uint8).detach().cpu()\n",
    "    \n",
    "\n",
    "def handle_slider(e):\n",
    "    renderer.visualizer.out.clear_output()\n",
    "    with renderer.visualizer.out:\n",
    "        renderer.visualizer.render_update()\n",
    "\n",
    "# Instantiate visualizer with this custom render function\n",
    "# camera.change_coordinate_system(\n",
    "#     torch.tensor(\n",
    "#         [[1, 0, 0],\n",
    "#          [0, 0, 1],\n",
    "#          [0, -1, 0]])\n",
    "# )\n",
    "# pitch=np.pi/2, yaw=np.pi/2\n",
    "# camera.rotate(roll=np.pi/8)\n",
    "focus_at = (camera.cam_pos() - 4. * camera.extrinsics.cam_forward()).squeeze()\n",
    "renderer.visualizer = kaolin.visualize.IpyTurntableVisualizer(\n",
    "    512, 512, copy.deepcopy(camera), timed_render_kaolin,\n",
    "    focus_at=focus_at, world_up_axis=2, max_fps=12)\n",
    "renderer.visualizer.render_update()\n",
    "\n",
    "scaling_slider.observe(handle_slider, names='value')\n",
    "opacity_slider.observe(handle_slider, names='value')\n",
    "attenuate_slider.observe(handle_slider, names='value')\n",
    "rescale_slider.observe(handle_slider, names='value')\n",
    "time_slider.observe(handle_slider, names='value')\n",
    "\n",
    "display(\n",
    "    renderer.visualizer.canvas,\n",
    "    time_slider,\n",
    "    # renderer.scaling_slider,\n",
    "    # renderer.opacity_slider,\n",
    "    # renderer.attenuate_slider,\n",
    "    # renderer.rescale_slider\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d0034f60-7644-42fe-a708-1f0f59743d4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.4244, device='cuda:0', grad_fn=<MinBackward1>)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gaussians.get_xyz[:,-1].min()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
